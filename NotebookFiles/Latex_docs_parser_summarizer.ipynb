{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Latex_docs_parser_summarizer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installation of required libraries"
      ],
      "metadata": {
        "id": "TP_xHotCrtDU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIOpeZnLafxh",
        "outputId": "4d666a6e-4140-400f-82de-934327f17e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pylatexenc in /usr/local/lib/python3.7/dist-packages (2.10)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: sumy in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.7/dist-packages (from sumy) (20.7.3)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.7/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from sumy) (2.23.0)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from sumy) (3.2.5)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.7/dist-packages (from breadability>=0.1.20->sumy) (4.2.6)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from breadability>=0.1.20->sumy) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.0.2->sumy) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (2021.10.8)\n"
          ]
        }
      ],
      "source": [
        "! pip install pylatexenc\n",
        "! pip install transformers                               \n",
        "# sentencepiece library for t5 transformers\n",
        "! pip install sentencepiece\n",
        "! pip install sumy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# class:LatexParser"
      ],
      "metadata": {
        "id": "EN62KAE23bP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from pylatexenc.latexwalker import LatexWalker, LatexEnvironmentNode\n",
        "from pylatexenc.latex2text import LatexNodes2Text\n",
        "\n",
        "\n",
        "def find_substring(s, start_string, end_string):\n",
        "    start = s.find(start_string) + len(start_string)\n",
        "    end = s.find(end_string)\n",
        "    substring = s[start:end]\n",
        "    return substring\n",
        "\n",
        "class LatexTextParser:\n",
        "\n",
        "    def __init__(self, file_path):\n",
        "        self.file_path = file_path\n",
        "        latex_file_list = open(file_path).readlines()\n",
        "        latex_file_wo_comments = []\n",
        "        # removal of comments in the latex files\n",
        "        for line in latex_file_list:\n",
        "            if not line.startswith(\"%\"):\n",
        "                latex_file_wo_comments.append(line)\n",
        "        self.latex_text_wo_comments = \"\".join(latex_file_wo_comments)\n",
        "\n",
        "    @staticmethod\n",
        "    def latex_extract_abstract_sections(latex_text_cleaned):\n",
        "        abstract = re.findall(r'\\\\begin{abstract}(.*?)\\\\end{abstract}', latex_text_cleaned, re.S)\n",
        "        section_names = re.findall(r'\\\\section{(.*?)}', latex_text_cleaned, re.S)\n",
        "        return abstract, section_names\n",
        "\n",
        "    @staticmethod\n",
        "    def get_sections_abstract_text(abstract, section_names, latex_text_cleaned):\n",
        "        section_content = dict()\n",
        "        sections_tags = []\n",
        "        for section in section_names:\n",
        "            section_tag = \"\\section{\" + section + \"}\"\n",
        "            sections_tags.append(section_tag)\n",
        "\n",
        "        sections_tags.append(\"\\end{document}\")\n",
        "\n",
        "        for section_index in range(len(sections_tags) - 1):\n",
        "            sections_text_latex = find_substring(latex_text_cleaned, sections_tags[section_index],\n",
        "                                                 sections_tags[section_index + 1])\n",
        "            sections_text = LatexNodes2Text().latex_to_text(sections_text_latex)\n",
        "            section_content[section_names[section_index]] = sections_text\n",
        "\n",
        "        abstract_text = LatexNodes2Text().latex_to_text(\"\".join(abstract))\n",
        "        section_content['abstract'] = abstract_text\n",
        "        return section_content\n",
        "\n",
        "    def latex_text_pre_processing(self):\n",
        "        figure_content = re.findall(r'\\\\begin{figure}(.*?)\\\\end{figure}', self.latex_text_wo_comments, re.S)\n",
        "        equation_content = re.findall(r'\\\\begin{equation}(.*?)\\\\end{equation}', self.latex_text_wo_comments, re.S)\n",
        "        table_content = re.findall(r'\\\\begin{table}(.*?)\\\\end{table}', self.latex_text_wo_comments, re.S)\n",
        "        latex_codes = table_content + equation_content + figure_content\n",
        "        latex_text_cleaned = self.latex_text_wo_comments\n",
        "        for latex_code in latex_codes:\n",
        "            latex_text_cleaned = latex_text_cleaned.replace(latex_code, \"\")\n",
        "        return latex_text_cleaned\n",
        "\n",
        "    def latex_text_parser(self):\n",
        "        latex_text_cleaned = self.latex_text_pre_processing()\n",
        "        abstract, section_names = self.latex_extract_abstract_sections(latex_text_cleaned)\n",
        "        section_content = self.get_sections_abstract_text(abstract, section_names, latex_text_cleaned)\n",
        "        return section_content, abstract, section_names\n",
        "\n"
      ],
      "metadata": {
        "id": "NgugN-wlahYq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# class:TextSummarizer"
      ],
      "metadata": {
        "id": "4_vvAc4-G4wQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sumy\n",
        "import gensim\n",
        "from gensim.summarization import summarize\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer, BartConfig,BartModel\n",
        "from transformers import XLMWithLMHeadModel, XLMTokenizer\n",
        "from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration\n",
        "from transformers import BigBirdPegasusForConditionalGeneration, AutoTokenizer\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "from bs4 import BeautifulSoup \n",
        "# Import the LexRank summarizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "# Importing the parser and tokenizer\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "# Import the LexRank summarizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "lex_rank_summarizer = LexRankSummarizer() \n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "lsa_summarizer=LsaSummarizer()\n",
        "# Parsing the text string using PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "\n",
        "\n",
        "class TextSummarizer:\n",
        "  def __init__(self):\n",
        "    # Instantiating the model and tokenizer bart\n",
        "    self.tokenizer_bart=BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "    self.model_bart=BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "    # Instantiating the model and tokenizer t5\n",
        "    self.model_t5 = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "    self.tokenizer_t5 = T5Tokenizer.from_pretrained('t5-small')\n",
        "    # Instantiating the model and tokenizer google_bigbird\n",
        "    self.model_BigBird = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\", attention_type=\"original_full\")\n",
        "    self.tokenizer_BigBird = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n",
        "    # by default encoder-attention is `block_sparse` with num_random_blocks=3, block_size=64\n",
        "    \n",
        "    self.tokenizer_Pegasus = PegasusTokenizer.from_pretrained('google/pegasus-xsum')\n",
        "    self.model_Pegasus = PegasusForConditionalGeneration.from_pretrained('google/pegasus-xsum')\n",
        "\n",
        "\n",
        "  def text_summarizer(self, text, min_len, max_len,num_sentences ):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    text_summary_dict = {}\n",
        "\n",
        "    text_summary_dict['_text_'] = text\n",
        "    # Encoding the inputs and passing them to model.generate()\n",
        "    inputs = self.tokenizer_bart.batch_encode_plus([text],return_tensors='pt',truncation=True)\n",
        "    summary_ids = self.model_bart.generate(inputs['input_ids'], early_stopping=True,min_length = min_len, max_length=max_len)\n",
        "    bart_summary = self.tokenizer_bart.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    # print(bart_summary)\n",
        "    text_summary_dict['bart_summary'] = bart_summary\n",
        "\n",
        "    inputs = self.tokenizer_BigBird(text, return_tensors='pt')\n",
        "    summary_ids = self.model_BigBird.generate(**inputs,min_length=min_len, max_length=max_len)\n",
        "    summary_BigBird = self.tokenizer_BigBird.batch_decode(summary_ids, skip_special_tokens=True)\n",
        "    text_summary_dict['summary_BigBird'] = summary_BigBird\n",
        "    print(summary_BigBird)\n",
        "\n",
        "    # google pegasus summarization\n",
        "\n",
        "    inputs = self.tokenizer_Pegasus([text], truncation=True, padding='longest', return_tensors=\"pt\")\n",
        "    summary_ids = self.model_Pegasus.generate(inputs['input_ids'], min_length=min_len, max_length=max_len)\n",
        "    summary_google_pegasus = self.tokenizer_Pegasus.batch_decode(summary_ids, skip_special_tokens=True)\n",
        "    text_summary_dict['summary_google_pegasus'] = summary_google_pegasus\n",
        "    \n",
        "    t5_text = \"summarize:\" + text\n",
        "    # encoding the input text\n",
        "    input_ids=self.tokenizer_t5.encode(t5_text, return_tensors='pt')\n",
        "    summary_ids = self.model_t5.generate(input_ids,early_stopping=True, min_length = min_len, max_length=max_len)\n",
        "    t5_summary = self.tokenizer_t5.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    text_summary_dict['t5_summary'] = t5_summary\n",
        "    # gensim_summary\n",
        "    summary_genensim = summarize(text)\n",
        "    text_summary_dict['gensim_summary'] = summary_genensim\n",
        "    my_parser = PlaintextParser.from_string(text,Tokenizer('english'))\n",
        "    lexrank_summary_sentences = lex_rank_summarizer(my_parser.document,sentences_count=num_sentences)\n",
        "    lexrank_summary = \"\"\n",
        "    for sentence in lexrank_summary_sentences:\n",
        "      lexrank_summary= lexrank_summary + \" \"+ str(sentence)\n",
        "    text_summary_dict['lexrank_summary'] = lexrank_summary\n",
        "    # creating the lsa summarizer\n",
        "    parser=PlaintextParser.from_string(text,Tokenizer('english'))\n",
        "    lsa_summary_sentences= lsa_summarizer(parser.document,num_sentences)\n",
        "    lsa_summary =\"\"\n",
        "    #  lsa summary\n",
        "    for sentence in lsa_summary_sentences:\n",
        "        lsa_summary= lsa_summary+\" \"+ str(sentence)\n",
        "    text_summary_dict['lsa_summary'] = lsa_summary\n",
        "    return text_summary_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibjyGPkhauZp",
        "outputId": "56ba4a59-8022-462e-96bf-7d7e31578afe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textSummarizer = TextSummarizer()"
      ],
      "metadata": {
        "id": "wy2I7mqhsZpX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = r\"/content/drive/MyDrive/TextSummarizationResults/main.tex\""
      ],
      "metadata": {
        "id": "LDfE04fiynoQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rx4T4NXy1XgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latex_text_parser = LatexTextParser(file_path)\n",
        "section_content_file, abstract_file, section_names_file = latex_text_parser.latex_text_parser()"
      ],
      "metadata": {
        "id": "SeX0Xv4A1Ewq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "section_names_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6XRhDBj1gFe",
        "outputId": "5b34f515-ef67-42ce-f69b-1f5a5a93a115"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Introduction',\n",
              " 'Algorithm Selection',\n",
              " 'Hybrid Ranking and Regression Losses',\n",
              " 'Models and Optimization',\n",
              " 'Evaluation',\n",
              " 'Conclusion']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_summary_dict = dict()\n",
        "for sections in section_names_file:\n",
        "  text_summary_dict[sections] = textSummarizer.text_summarizer(section_content_file[sections],100,150,4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqqBwRUc1858",
        "outputId": "e2f5ed8e-8c4b-4fe0-a10c-707f1bf96b77"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['we consider the problem of automatically selecting an algorithm from a set of algorithms, which is suitable for a given instance of the problem for a given class of candidate algorithms.<n> the problem of automatically selecting an algorithm from a set of algorithms, which is suitable for a given instance of the problem for a given class of candidate algorithms, is a typical example of computationally hard problems.<n> typical application of such selection solvers for such problem include the problem of automatically selecting an algorithm from a set of algorithms, which is suitable for a given instance of the problem for a given class of candidate algorithms. in this paper, we consider the problem of automatically selecting an algorithm from a set of algorithms, which is suitable for a']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (869 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['in this paper, we consider the classification problem of regression where the goal is to find a set of linear regression models which are consistent with a given set of test data.<n> we show that this problem can be reduced to the classification problem of regression where the goal is to find a set of linear regression models which are consistent with a given set of test data.<n> we show that this problem can be reduced to the classification problem of regression where the goal is to find a set of linear regression models which are consistent with a given set of test data.<n> we show that this problem can be reduced to the classification problem of regression where the goal is to find a set of linear regression models which are consistent with a given set of']\n",
            "['in this paper, we consider the problem of learning a regression model.<n> we introduce a new framework for learning a regression model.<n> we show that learning a regression model is in general not a ranking problem.<n> we also show that learning a regression model is in general not a ranking problem. <n> [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ']\n",
            "['in this paper, we consider the problem of selecting the best subset of parameters to model a given function.<n> we consider three types of models, namely linear models, namely linear models, and neural networks, models define score of the function.<n> we consider the problem of selecting the best subset of parameters to model a given function.<n> we consider three types of models, namely linear models, namely linear models, and neural networks, models define score of the function. <n> we consider the problem of selecting the best subset of parameters to model a given function.<n> we consider three types of models, namely linear models, namely linear models, and neural networks ']\n",
            "['this paper presents a new approach to the regression selection problem.<n> the proposed approach is based on a hybrid neural network approach.<n> the performance of the proposed algorithm is compared with that of several state - of - the - art regression algorithms.<n> we show that the performance of the proposed algorithm is close to that of the state - of - the - art in several aspects.<n> in particular, we show that the performance of the proposed algorithm is close to that of the state - of - the - art in several aspects : ( i ) the proposed algorithm achieves the best performance in several aspects among the state - of - the - art algorithms ; ( ii ) the proposed algorithm achieves the best performance in']\n",
            "['this is the first of a series of papers dedicated to the numerical analysis of regression loss functions.<n> we advocated the use of hybrid ranking and regression for the regression selection problem with special attention to three classes of models for estimating performances, namely linear models, namely nonlinear models in form of neural networks.<n> results obtained by our experimental evaluation confirm that considering both ranking objectives often leads to better algorithm choices than relying one of two approaches on convex objectives.  work was supported in part by the grant - in - aid for scientific and educational programming ( biaps ) of the united states of america.  work was supported in part by the grant - in - aid for scientific and educational programming ( biap']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_summary_dict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGNxdD_D2mne",
        "outputId": "c626ab70-bc6b-4eaa-b1d6-70009f552730"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Algorithm Selection': {'_text_': '\\n\\nIn the (per-instance) algorithm selection problem, first introduced by Rice <cit.>, one is concerned with automatically selecting the most suitable algorithm from a set of candidate algorithms 𝒜  = {A_1,…,A_K} for a specific instance I ∈ℐ of an algorithmic problem class such as the Boolean satisfiability problem (SAT). Formally, the goal is to find a mapping s ℐ→𝒜, also referred to as algorithm selector, from a problem instance space ℐ to the set of candidate algorithms 𝒜, which optimizes a costly-to-evaluate performance measure m ℐ×𝒜→ℝ of interest. The arguably most relevant example of such a measure, which is also considered in this paper, is runtime. The optimal algorithm selector (the oracle) is defined as\\n\\n    \\n \\nfor I ∈ℐ, where the expectation accounts for the potential randomness of the algorithm (and any other random effects causing the performance of A on I to be non-deterministic).\\n\\n\\n\\n §.§ Existing Approaches\\n\\nTo evaluate the performance measure m, an algorithm normally needs to be run on a given problem instance. This makes an exhaustive search over the algorithm space 𝒜 computationally intractable or at least extremely costly. To circumvent this problem, a surrogate model m: ℐ×𝒜→ℝ can be used to estimate the performance. Such models, which should be cheap to evaluate, are trained on data collected from previous algorithm runs. A feature extraction function f ℐ→ℝ^d is used to compute d-dimensional feature representations of problem instances, which then allow for modeling the algorithm performance as functions of instance features. To keep the notation simple, we will not distinguish between I and f(I) in the remainder of this paper; instead, we denote both a problem instance and its feature representation by I. Using such a model, the canonical algorithm selector will suggest the algorithm A with the lowest predicted runtime on the instance I:\\n\\n    \\n\\nA natural choice for m is an algorithm-specific regression model m_k ℐ→ℝ, directly estimating the runtime achieved by an algorithm A_k ∈𝒜 on a problem instance of interest I ∈ℐ <cit.>.\\n\\nEarly work on such surrogates can be found in <cit.>, where the authors tackle the winner determination problem for the CPLEX solver. They demonstrate that, under certain conditions, the hardness of an instance represented by features, i.e., the expected performance of an algorithm on that instance, can be learned using machine learning approaches. Both linear and nonlinear models (multivariate adaptive regression splines <cit.>) were successfully applied for modeling the hardness of an instance (with respect to the root mean squared error).\\n\\nIn one of the earlier versions of the well-known algorithm selection approach Satzilla <cit.>, the authors leverage such empirical hardness models on a per-algorithm basis. To this end, they learn one linear model per algorithm using ridge regression, which estimates its performance for unseen instances based on associated features.\\n\\nSimilarly, restart strategies are selected based on conditional runtime prediction models in <cit.>. These models are inferred through ridge linear regression conditioned on the satisfiability of an instance. Instead of directly selecting an algorithm based on the predicted runtime, the authors of <cit.> use regression techniques in a more indirect way: The runtimes predicted by random forests are used to map instances into another feature space, in which k-nearest neighbor methods are then applied to make the final selection. \\n\\n\\nAs already explained in the introduction, an accurate prediction of runtimes is a sufficient but not necessary condition for selecting the best performing algorithm. Actually, such a selection rather corresponds to a classification instead of a regression problem, with the algorithms playing the role of the classes. Training a classifier, however, has a number of disadvantages. For example, by looking at the best algorithm only, large parts of the training data would be ignored. Likewise, recommendations are not very informative in this setting, as they do not differentiate between the (presumably) non-optimal algorithms. Alternatively, the AS problem could also be tackled as a ranking task, which can be seen as a compromise between classification and regression.\\n\\nRanking methods have been developed in the field of preference learning. Specifically relevant in the context of AS is so-called label ranking (LR) <cit.>. Here, instances are associated with rankings over a set of choice alternatives, in our case algorithms.  \\nThus, training data is of the form \\n\\n    \\n\\nwhere ℛ(𝒜) is the set of all total orders on 𝒜, and A_i ≻ A_j suggests that algorithm A_i performs better than algorithm A_j. What is then sought is a model h:  ℝ^d →ℛ(𝒜), which, given an instance I ∈ℐ (resp. its feature representation f(I)), predicts a ranking over the set of candidate algorithms 𝒜. A recommendation can then be derived from that ranking, for example in the form of the top-1 or more generally top-k candidates. \\nAn example of label ranking applied to AS can be found in <cit.>, where the authors infer rankings of collaborative filtering algorithms for instances of recommendation problems. \\nSimilarly, the authors of <cit.> use neural network based LR techniques to select meta-heuristics for travelling salesman problem instances.\\n\\nIn <cit.>, dyadic approaches to ranking and regression are presented, which do not only leverage instance but also algorithm features, allowing one to select from an extremely large set of algorithms. A ranking method based on the Plackett-Luce model is shown to perform very well in a setting with many algorithms and very few training data, called extreme algorithm selection.\\nSimilarly, <cit.> leverage a ranking approach motivated  from a Bayesian perspective, where the joint utility score of a pair of algorithms for an instance is defined in terms of the difference of the individual utility scores.\\n\\nFor a comprehensive and up-to-date survey of methods for algorithm selection, we refer to <cit.>. \\n\\n',\n",
              "  'bart_summary': 'In the (per-instance) algorithm selection problem, first introduced by Rice <cit.>, one is concerned with automatically selecting the most suitable algorithm from a set of candidate algorithms. The goal is to find a mapping s ℐ→𝒜, also referred to as algorithm selector, which optimizes a costly-to-evaluate performance measure m of interest. To evaluate the performance measure, an algorithm normally needs to be run on a given problem instance. This makes an exhaustive search over the algorithm space computationally intractable.',\n",
              "  'gensim_summary': 'Formally, the goal is to find a mapping s ℐ→𝒜, also referred to as algorithm selector, from a problem instance space ℐ to the set of candidate algorithms 𝒜, which optimizes a costly-to-evaluate performance measure m ℐ×𝒜→ℝ of interest.\\nA natural choice for m is an algorithm-specific regression model m_k ℐ→ℝ, directly estimating the runtime achieved by an algorithm A_k ∈𝒜 on a problem instance of interest I ∈ℐ <cit.>.\\nTo this end, they learn one linear model per algorithm using ridge regression, which estimates its performance for unseen instances based on associated features.\\nSimilarly, restart strategies are selected based on conditional runtime prediction models in <cit.>.\\nInstead of directly selecting an algorithm based on the predicted runtime, the authors of <cit.> use regression techniques in a more indirect way: The runtimes predicted by random forests are used to map instances into another feature space, in which k-nearest neighbor methods are then applied to make the final selection.\\nits feature representation f(I)), predicts a ranking over the set of candidate algorithms 𝒜.\\nIn <cit.>, dyadic approaches to ranking and regression are presented, which do not only leverage instance but also algorithm features, allowing one to select from an extremely large set of algorithms.\\nA ranking method based on the Plackett-Luce model is shown to perform very well in a setting with many algorithms and very few training data, called extreme algorithm selection.',\n",
              "  'lexrank_summary': ' To keep the notation simple, we will not distinguish between I and f(I) in the remainder of this paper; instead, we denote both a problem instance and its feature representation by I. its feature representation f(I)), predicts a ranking over the set of candidate algorithms 𝒜. An example of label ranking applied to AS can be found in <cit.>, where the authors infer rankings of collaborative filtering algorithms for instances of recommendation problems. In <cit.>, dyadic approaches to ranking and regression are presented, which do not only leverage instance but also algorithm features, allowing one to select from an extremely large set of algorithms.',\n",
              "  'lsa_summary': ' This makes an exhaustive search over the algorithm space 𝒜 computationally intractable or at least extremely costly. Such models, which should be cheap to evaluate, are trained on data collected from previous algorithm runs. To this end, they learn one linear model per algorithm using ridge regression, which estimates its performance for unseen instances based on associated features. Similarly, the authors of <cit.> use neural network based LR techniques to select meta-heuristics for travelling salesman problem instances.',\n",
              "  'summary_BigBird': ['in this paper, we consider the classification problem of regression where the goal is to find a set of linear regression models which are consistent with a given set of test data.<n> we show that this problem can be reduced to the classification problem of regression where the goal is to find a set of linear regression models which are consistent with a given set of test data.<n> we show that this problem can be reduced to the classification problem of regression where the goal is to find a set of linear regression models which are consistent with a given set of test data.<n> we show that this problem can be reduced to the classification problem of regression where the goal is to find a set of linear regression models which are consistent with a given set of'],\n",
              "  'summary_google_pegasus': ['In this paper, we present a new approach to the (per-instance) algorithm selection problem, using a surrogate model m: IAR, to estimate the runtime achieved by an algorithm A on a problem instance of interest I I cit.>, where the expected performance of an algorithm on that instance is the runtime achieved by an algorithm A on a problem instance of interest I I cit.>, where the expected performance of an algorithm A on that instance is the runtime achieved by an algorithm A on a problem instance of interest I I cit.>, where the expected performance of an algorithm A on that instance is the runtime achieved by an algorithm A'],\n",
              "  't5_summary': 'algorithm selection problem is first introduced by rice cit. the authors use ridge linear regression to predict runtime. a ranking method is used to select a classifier based on the satisfiability of an instance. a ranking method is used to select a ranking algorithm from a set of candidates. a ranking method is used to select a ranking algorithm from a set of candidates. a ranking method is used to select a ranking algorithm from a set of candidates'},\n",
              " 'Conclusion': {'_text_': '\\nIn this paper, we advocated the use of hybrid ranking and regression for the algorithm selection problem, mainly with the objective to tackle the “right” problem — which is selection, or, more generally, ranking — while not losing potentially useful numerical information about observed performances (runtimes). \\nThe proposed framework is built upon optimizing combined loss functions that take both regression and ranking criteria into account. We investigated three classes of models for estimating algorithm performances, namely linear models, quadratic models, and non-linear models in the form of neural networks. The results obtained by our experimental evaluation confirm that considering both ranking and regression objectives often leads to better algorithm choices than solely relying on one of the two objectives.\\n\\nThe proposed approaches rely on minimizing a convex combination of a ranking and a regression loss function. We investigated the squared hinge ranking loss and a ranking loss based on the Plackett-Luce model in combination with the mean squared error as a regression loss. In future work, we plan to further elaborate on suitable hybrid losses and to investigate the performance of other combinations. Of particular interest are regression methods for censored data, as these allow for modeling timeouts in a theoretically sound way. Another important question concerns the influence of the hyperparameter λ, which balances the regression and the ranking objectives. As we did not observe a suitable default value, it would be interesting to identify properties of algorithm selection scenarios that seem to influence the optimal choice of this parameter, i.e., which allow for deciding which of the two objectives, regression or ranking, should be emphasized more.\\n\\n\\n\\n  §.§.§ Acknowledgements.\\n\\nThis work was supported by the German Federal Ministry of Economic Affairs and Energy (BMWi) within the “Innovationswettbewerb Künstliche Intelligenz” and the German Research Foundation (DFG) within the Collaborative Research Center “On-The-Fly Computing” (SFB 901/3 project no. 160364472).\\nThe authors also gratefully acknowledge support of this project through computing time provided by the Paderborn Center for Parallel Computing (PC^2).\\n\\nsplncs04\\n\\n',\n",
              "  'bart_summary': 'The proposed framework is built upon optimizing combined loss functions that take both regression and ranking criteria into account. The results obtained by our experimental evaluation confirm that considering both ranking and regression objectives often leads to better algorithm choices than solely relying on one of the two objectives. Of particular interest are regression methods for censored data, as these allow for modeling timeouts in a theoretically sound way. Another important question concerns the influence of the hyperparameter λ, which balances the regression and the ranking objectives. It would be interesting to identify properties of algorithm selection scenarios that seem to influence the optimal choice of this parameter.',\n",
              "  'gensim_summary': 'The proposed approaches rely on minimizing a convex combination of a ranking and a regression loss function.\\nAs we did not observe a suitable default value, it would be interesting to identify properties of algorithm selection scenarios that seem to influence the optimal choice of this parameter, i.e., which allow for deciding which of the two objectives, regression or ranking, should be emphasized more.',\n",
              "  'lexrank_summary': ' We investigated three classes of models for estimating algorithm performances, namely linear models, quadratic models, and non-linear models in the form of neural networks. Of particular interest are regression methods for censored data, as these allow for modeling timeouts in a theoretically sound way. As we did not observe a suitable default value, it would be interesting to identify properties of algorithm selection scenarios that seem to influence the optimal choice of this parameter, i.e., which allow for deciding which of the two objectives, regression or ranking, should be emphasized more. §.§.§ Acknowledgements.',\n",
              "  'lsa_summary': ' The proposed framework is built upon optimizing combined loss functions that take both regression and ranking criteria into account. The results obtained by our experimental evaluation confirm that considering both ranking and regression objectives often leads to better algorithm choices than solely relying on one of the two objectives. As we did not observe a suitable default value, it would be interesting to identify properties of algorithm selection scenarios that seem to influence the optimal choice of this parameter, i.e., which allow for deciding which of the two objectives, regression or ranking, should be emphasized more. The authors also gratefully acknowledge support of this project through computing time provided by the Paderborn Center for Parallel Computing (PC^2).',\n",
              "  'summary_BigBird': ['this is the first of a series of papers dedicated to the numerical analysis of regression loss functions.<n> we advocated the use of hybrid ranking and regression for the regression selection problem with special attention to three classes of models for estimating performances, namely linear models, namely nonlinear models in form of neural networks.<n> results obtained by our experimental evaluation confirm that considering both ranking objectives often leads to better algorithm choices than relying one of two approaches on convex objectives.  work was supported in part by the grant - in - aid for scientific and educational programming ( biaps ) of the united states of america.  work was supported in part by the grant - in - aid for scientific and educational programming ( biap'],\n",
              "  'summary_google_pegasus': ['Selection algorithms are often confronted with the question of which of the two objectives, regression or ranking, should be the goal and which should be the goal only, i.e., which one of the two objectives, regression or ranking, should be the goal and which one of the two objectives, ranking, should be the goal and which one of the two objectives, ranking, should be the goal and which one of the two objectives, ranking, should be the goal and which one of the two objectives, ranking, should be the goal and which one of the two objectives, ranking, should be the goal and which one of the two objectives, ranking, should be the goal and which one of the two objectives, ranking, should be the'],\n",
              "  't5_summary': 'the proposed framework is built upon optimizing combined loss functions. the results obtained by our experimental evaluation confirm that considering both ranking and regression objectives often leads to better algorithm choices than solely relying on one of the two objectives. the proposed approaches rely on minimizing a convex combination of a ranking and a regression loss function. the proposed approaches rely on minimizing a convex combination of a ranking and a regression loss function.'},\n",
              " 'Evaluation': {'_text_': \"\\nIn order to evaluate the performance of the proposed hybrid ranking and regression approach to the algorithm selection problem, we make use of the ASlib benchmark <cit.>. This benchmark contains several AS scenarios, which are collections of performance data of algorithms achieved on several problem instances. As we consider runtime as a selection criterion in the scope of this paper, we evaluated our approach using scenarios from the algorithmic problem domains of Boolean satisfiability (SAT), mixed integer programming (MIP), constraint satiscation (CSP), and container pre-marshalling (CPMP). \\n\\n\\n\\n §.§ Performance Metrics\\n\\nFor assessing the performance achieved by the proposed approaches, we consider both ranking measures as well as specific algorithm selection measures. Ranking measures quantify how well the ranking over algorithms according to their predicted performance corresponds to the ranking implied by their true performance. We represent a ranking of the algorithms {A_1,…,A_K} in terms of a mapping π [K] → [K], such that π(k) is the position of the algorithm A_k in the ranking — allowing for ties[Ties are mainly caused by timeouts in the “ground truth” data but rarely occur in the predicted performances.], we may have π(i) = π(j) for i ≠ j. One prominent measure is the rank correlation coefficient Kendall's tau <cit.>. Given a ground truth ranking π and a predicted ranking π̂, Kendall's τ is defined as \\n\\n    \\n \\nwhere C is the number of correctly ordered pairs ((π(i)-π(j))(π̂(i)-π̂(j)) > 0), D is the number of incorrectly ordered pairs ((π(i)-π(j))(π̂(i)-π̂(j)) < 0), and T_π and T_π̂ are the number of ties in ranking π and π̂, respectively. Kendall's τ takes values in [-1,1], where τ(π,π̂) = 1 means that the rankings π̂ and π are in perfect agreement and τ(π,π̂) = -1 the exact opposite (one of them is the reversal of the other one).\\n\\nA widespread performance measure in the field of AS with respect to runtime is the penalized average runtime with a penalty factor of 10 (PAR10). Typically, the algorithms for the problem domains considered in this paper are not run for an indefinite amount of time until they eventually terminate, but are rather aborted after a predefined timeout is exceeded. The PAR10 score simply averages the runtime achieved by the selected algorithms for all problem instances of a scenario and accounts for timed out runs with 10 times the timeout as their runtime. We ignore feature costs, i.e., the runtime of the feature extraction function f, when computing PAR10 scores, as not all of the considered scenarios provide this information.\\n\\n\\n\\n §.§ Evaluation Setup\\n\\nThe experimental results were obtained by conducting a 10-fold cross validation. In each fold, a fraction of 90% of a scenario's problem instances and the corresponding algorithm performances was used for training the algorithm selector, and the remaining 10% were used as a test set. For each scenario, we used the full set of features provided by ASLib <cit.>. Missing feature values were imputed with the feature's mean. Afterwards, feature values were standardized before training the models. Algorithm runtimes are given in terms of the PAR10 format, i.e., timed out runs are accounted for with 10-times the timeout. \\nAs the set of pairwise preferences P_n grows quadratically in the number of candidate algorithms, we approximate it by a sample P̂_n containing at most 5 pairwise algorithm comparisons for each instance. Should this number of comparisons not be available, we sample the maximum number of possible comparisons. \\n\\n To evaluate the influence of the hyperparameter λ on the predictive performance, we conducted the experiments for λ∈{0.0,0.1,…,1.0}.\\n For training the linear and quadratic models, we set the regularization parameter γ = 10^-3 and ran the L-BFGS-B <cit.> algorithm for at most 100 iterations in order to minimize the loss functions.\\nFor the neural network-based approaches, we used the Adam <cit.> optimizer with a learning rate of η = 10^-3 for minimizing the loss functions and a batch size of 128. The architecture consists of a single hidden layer with 32 nodes, each using the sigmoid activation function t ↦1/1 + e^-t.\\nFor early stopping, a fraction of 0.3 of the original training data is used as a validation set. We compute the loss on this validation set every 8 epochs and stop the training procedure if it increases for 8 consecutive checks. After the training, the model weights are set to the values for which the best validation loss was observed. If early stopping does not apply, the training procedure is stopped after a maximum number of 1,000 epochs. We evaluated the performance metrics for six independent runs on different random seeds and aggregated them by averaging the results.\\n\\nThe implementation of the proposed approaches including a documentation is provided on GitHub[https://github.com/JonasHanselle/CoRRAS].\\n\\n\\n\\n\\n §.§ Results\\n\\nIn the following, we discuss the results obtained by the experimental evaluation for all considered approaches, i.e., the two ranking loss functions in combination with the mean squared error as regression loss: the linear models (PL-LM, Hinge-LM), the quadratic models (PL-QM, Hinge-QM), and the neural networks (PL-NN, Hinge-NN). Figure <ref> shows the average Kendall's τ rank correlation achieved by each of the proposed approaches for several values of λ. Recall that lower values of λ correspond to emphasizing the regression objective while higher values correspond to emphasizing the ranking objective. At first glance, we observe a tendency that larger values for λ lead to better rankings. Notably, however, in various cases the peak performance is not achieved for λ=1, but rather for a proper compromise between ranking and regression. Consider for example the MIP-2016, SAT11-RAND or SAT11-HAND scenario, for which several of the proposed approaches achieve their peak performance for intermediate λ values. \\n\\n\\n\\nFigure <ref> shows the PAR10 scores achieved by the proposed approaches. Again, we observe that neither pure regression nor pure ranking achieve the best performance consistently. Instead, a combination of the two appears to be favorable for most of the AS scenarios. Especially in the CSP-2010 and the MIP-2016 scenarios, the best performances, i.e. lowest PAR10 scores, are achieved for most of the proposed models when considering a hybrid ranking and regression loss.\\n\\n\\n\\nTable <ref> shows the number of scenarios for which a pure regression approach (λ=0), a pure ranking approach (λ = 1), or a hybrid ranking and regression approach (λ∈{0.1, … , 0.9 }) achieves the best performances according to Kendall's τ and the PAR10 score. Regarding the rank correlation, unsurprisingly none of the proposed models achieved the best performance with the pure regression setting. The hybrid ranking and regression results are either on par with pure label ranking results or ahead of them. With respect to the PAR10 scores, hybrid regression and ranking performs the best for all model-loss combinations. Overall, for the majority of model-scenario combinations, a hybrid regression and ranking approach performs the best. While setting the hyperparameter λ to an intermediate value yields promising results, we could not reliably identify an optimal default value for this parameter. Instead, as can be seen in the plots in Figures <ref> and <ref>, the value for which the best performance is achieved depends both on the model and the scenario at hand. \\n\\n\\n\\n\",\n",
              "  'bart_summary': 'We evaluate the performance of the proposed hybrid ranking and regression approach to the algorithm selection problem. We consider both ranking measures as well as specific algorithm selection measures. The experimental results were obtained by conducting a 10-fold cross validation. For the training quadratic and regularization parameters, we ran the regularization set for at most 100 iterations in order to minimize the loss functions. The neural network architecture consists of a single hidden layer with 32 nodes, each using the sigmoid activation function. We used the optimizer Adam <cit> as a validation set on every data set.',\n",
              "  'gensim_summary': \"In order to evaluate the performance of the proposed hybrid ranking and regression approach to the algorithm selection problem, we make use of the ASlib benchmark <cit.>.\\nAs we consider runtime as a selection criterion in the scope of this paper, we evaluated our approach using scenarios from the algorithmic problem domains of Boolean satisfiability (SAT), mixed integer programming (MIP), constraint satiscation (CSP), and container pre-marshalling (CPMP).\\nThe PAR10 score simply averages the runtime achieved by the selected algorithms for all problem instances of a scenario and accounts for timed out runs with 10 times the timeout as their runtime.\\nIn the following, we discuss the results obtained by the experimental evaluation for all considered approaches, i.e., the two ranking loss functions in combination with the mean squared error as regression loss: the linear models (PL-LM, Hinge-LM), the quadratic models (PL-QM, Hinge-QM), and the neural networks (PL-NN, Hinge-NN).\\nFigure <ref> shows the average Kendall's τ rank correlation achieved by each of the proposed approaches for several values of λ.\\nEspecially in the CSP-2010 and the MIP-2016 scenarios, the best performances, i.e. lowest PAR10 scores, are achieved for most of the proposed models when considering a hybrid ranking and regression loss.\\nTable <ref> shows the number of scenarios for which a pure regression approach (λ=0), a pure ranking approach (λ = 1), or a hybrid ranking and regression approach (λ∈{0.1, … , 0.9 }) achieves the best performances according to Kendall's τ and the PAR10 score.\\nRegarding the rank correlation, unsurprisingly none of the proposed models achieved the best performance with the pure regression setting.\\nWith respect to the PAR10 scores, hybrid regression and ranking performs the best for all model-loss combinations.\\nOverall, for the majority of model-scenario combinations, a hybrid regression and ranking approach performs the best.\",\n",
              "  'lexrank_summary': \" In order to evaluate the performance of the proposed hybrid ranking and regression approach to the algorithm selection problem, we make use of the ASlib benchmark <cit.>. In the following, we discuss the results obtained by the experimental evaluation for all considered approaches, i.e., the two ranking loss functions in combination with the mean squared error as regression loss: the linear models (PL-LM, Hinge-LM), the quadratic models (PL-QM, Hinge-QM), and the neural networks (PL-NN, Hinge-NN). Especially in the CSP-2010 and the MIP-2016 scenarios, the best performances, i.e. lowest PAR10 scores, are achieved for most of the proposed models when considering a hybrid ranking and regression loss. Table <ref> shows the number of scenarios for which a pure regression approach (λ=0), a pure ranking approach (λ = 1), or a hybrid ranking and regression approach (λ∈{0.1, … , 0.9 }) achieves the best performances according to Kendall's τ and the PAR10 score.\",\n",
              "  'lsa_summary': ' As we consider runtime as a selection criterion in the scope of this paper, we evaluated our approach using scenarios from the algorithmic problem domains of Boolean satisfiability (SAT), mixed integer programming (MIP), constraint satiscation (CSP), and container pre-marshalling (CPMP). Typically, the algorithms for the problem domains considered in this paper are not run for an indefinite amount of time until they eventually terminate, but are rather aborted after a predefined timeout is exceeded. If early stopping does not apply, the training procedure is stopped after a maximum number of 1,000 epochs. At first glance, we observe a tendency that larger values for λ lead to better rankings.',\n",
              "  'summary_BigBird': ['this paper presents a new approach to the regression selection problem.<n> the proposed approach is based on a hybrid neural network approach.<n> the performance of the proposed algorithm is compared with that of several state - of - the - art regression algorithms.<n> we show that the performance of the proposed algorithm is close to that of the state - of - the - art in several aspects.<n> in particular, we show that the performance of the proposed algorithm is close to that of the state - of - the - art in several aspects : ( i ) the proposed algorithm achieves the best performance in several aspects among the state - of - the - art algorithms ; ( ii ) the proposed algorithm achieves the best performance in'],\n",
              "  'summary_google_pegasus': ['The goal of this paper is to develop a hybrid ranking and regression approach to the algorithm selection problem in the field of artificial intelligence (AS) by using runtime as a selection criterion in the scope of the scope of this paper.. Performance Metrics For assessing the performance achieved by the proposed approaches, we consider both ranking measures as well as specific algorithm selection measures.. Performance Metrics for assessing the performance achieved by the proposed approaches, we consider both ranking measures as well as specific algorithm selection measures.. Performance Metrics for assessing the performance achieved by the proposed approaches, we consider both ranking measures as well as specific algorithm selection measures.'],\n",
              "  't5_summary': 'a hybrid ranking and ranking approach performs the best for all model-loss combinations. the hybrid ranking and ranking approach is either on par with pure label ranking results or ahead of them. the results are based on the results of the proposed approaches. the results are presented on a GitHub repository. the results are presented in the following table. a re-analysis of the proposed approaches is based on the results of the proposed approaches.'},\n",
              " 'Hybrid Ranking and Regression Losses': {'_text_': \"\\n\\n\\nThere are several motivations for casting AS as a (label) ranking instead of a regression problem. As already explained, ranking not only appears to be the simpler task, but actually also the “right” problem. Indeed, the goal of AS is better reflected by a (non-symmetric) ranking than by a (symmetric) regression loss. Besides, precise numerical performance degrees are not always observable, for example when an algorithm is timed out, leading to missing or censored data in the case of regression, while preferences can still be derived. \\nOn the other hand, if precise performances are available, then considering only the qualitative part of the training information, namely the order relations, comes with a certain loss of information. For example, information about the algorithms' actual performance degrees, and the differences between them, may provide useful information about the reliability of a (pairwise) comparison. \\n\\nThese considerations suggest that both aspects should be taken into account when training an algorithm selector: predicted runtimes should first of all match the order of algorithms, and if possible, even be close to the actually observed runtimes. This could be accomplished by training the predictor with a hybrid loss function that combines both aspects into a single criterion.\\n\\nTherefore, we propose the use of hybrid ranking and regression approaches for the AS problem. To this end, we model the performance of each algorithm in the candidate set A_k ∈𝒜 in terms of a scoring function v_k ℐ→ℝ. As will be seen, the scoring function is in direct correspondence to the performance measure m_k, though not necessarily the same. The overall scoring model v is then given by v(I ,A_k)  v_k(I). \\nSimilar to the original combined regression and ranking approach presented by Sculley <cit.>, our hybrid loss functions are based on a convex combination of a ranking term L_RANK that imposes ordering constraints between the individual predictions v_k(I), k ∈ [K] {1, … , K }, and a regression term L_REG that relates v_k to the actual runtime m(I,A_k) achieved by algorithm A_k on the respective instance I. \\n\\n\\n\\n\\n §.§ Training Data\\n\\n\\nAs training data, we assume (possibly incomplete or partial) information about the performance of algorithms on a set of training instances I_1, … , I_N ∈ℐ:\\n\\n    \\n\\nwhere m_k'(I_n) is information about the performance (runtime) of algorithm A_k on the instance I_n. Usually, m_k'(I_n) is the runtime itself, however, the performance is also allowed to be unknown (m_k'(I_n) =), for example because the algorithm has not been executed. Moreover, m_k'(I_n) might be censored information about the true performance. A practically motivated example of such information is a timeout (m_k'(I_n) = TO): algorithm A_k has been run on I_n, but not till the end, because it did not terminate within a given time frame.    \\n\\nFrom the information about each of the N instances I_n, we construct a set of training examples R_n for a regression learner and a set of training examples P_n for a preference learner. For regression, if m_k'(I_n) ≠, we include an example (I_n, y_k,n) which is normalized by the timeout T_max, namely y_k,n = 1 if m_k'(I_n) = TO and y_k,n = m_k'(I_n)/T_max. In the case where m_k'(I_n) =, no information about A_k is included in R_n.\\n\\nThe set P_n consists of pairwise preferences of the form A_i≻ A_j, suggesting that algorithm A_i performed better on I_n than algorithm A_j. We include such a preference, which we formally represent as (I_n, i , j), whenever one of the following conditions holds:\\n\\n\\n  * m_i'(I_n) ∉{, TO}, m_j'(I_n) ∉{, TO}, m_i'(I_n) < m_j'(I_n),\\n\\n  * m_i'(I_n) ∉{, TO}, m_j'(I_n) = TO.\\n\\n\\n\\n\\n \\n \\n\\n\\n §.§ Loss Functions\\n\\n\\n\\n\\nAs already said, the overall loss of a model v on a dataset 𝒟 is a convex combination of a ranking and a regression loss:\\n\\n    \\n\\nwhere the hyperparameter λ∈ [0,1] can be tuned to balance the two objectives. Setting λ = 0 corresponds to a pure regression model, whereas λ=1 results in a pure ranking model. \\n\\nIn general, any ranking loss L_RANK and any  regression loss L_REG can be used to instantiate our generic framework. Here, we model the latter in terms of the mean squared error (MSE)\\n\\n    \\n\\nThe overall loss L_REG(𝒟,v) is then obtained by averaging (<ref>) over all N training instances. \\n\\n\\nFor ranking, we consider the squared hinge ranking loss given by\\n\\n    \\n\\nwhere ϵ∈ℝ^+ is a margin and ℓ(x) = (max{ 0, x })^2. This loss function is a smooth convex approximation of the \\nsimple 0/1 loss and enforces a margin effect in the sense that, to have a loss of 0, the two predictions must be correctly ordered and have a distance of at least ϵ. Again, the loss on the entire data, L_RANK(𝒟, v) is obtained by averaging over all N training instances. For computational reasons, since L_RANK(P_n,v) contains a quadratic number of preferences, one may consider approximating this loss by sampling a subset of these preferences.\\n\\nAs an alternative to the squared hinge ranking loss (<ref>), we also consider the following loss:\\n\\n    \\n\\nwith \\n\\n    \\n\\nThis loss corresponds to the negative log-likelihood of observing a pairwise preference under the Plackett-Luce (PL) model for ranking data <cit.>, which is commonly used in preference learning and label ranking <cit.>. \\n\\n\\n\\n\\n\",\n",
              "  'bart_summary': 'The goal of AS is better reflected by a ranking than by a (symmetric) regression loss. We model the performance of each algorithm in the candidate set A_k in terms of a scoring function. The overall scoring model v is then given by v(I,A_k)  v_k(I). The overall loss of a model on a dataset is a convex combination of a ranking term L_RANK and a regression term L-REG. We assume (possibly incomplete or partial) information about performance of algorithms on a set of training instances I_1, …, I_N.',\n",
              "  'gensim_summary': 'Besides, precise numerical performance degrees are not always observable, for example when an algorithm is timed out, leading to missing or censored data in the case of regression, while preferences can still be derived.\\nOn the other hand, if precise performances are available, then considering only the qualitative part of the training information, namely the order relations, comes with a certain loss of information.\\nTo this end, we model the performance of each algorithm in the candidate set A_k ∈𝒜 in terms of a scoring function v_k ℐ→ℝ.\\nSimilar to the original combined regression and ranking approach presented by Sculley <cit.>, our hybrid loss functions are based on a convex combination of a ranking term L_RANK that imposes ordering constraints between the individual predictions v_k(I), k ∈ [K] {1, … , K }, and a regression term L_REG that relates v_k to the actual runtime m(I,A_k) achieved by algorithm A_k on the respective instance I.\\nAs training data, we assume (possibly incomplete or partial) information about the performance of algorithms on a set of training instances I_1, … , I_N ∈ℐ:\\nAs already said, the overall loss of a model v on a dataset 𝒟 is a convex combination of a ranking and a regression loss:\\nAgain, the loss on the entire data, L_RANK(𝒟, v) is obtained by averaging over all N training instances.',\n",
              "  'lexrank_summary': \" To this end, we model the performance of each algorithm in the candidate set A_k ∈𝒜 in terms of a scoring function v_k ℐ→ℝ. As training data, we assume (possibly incomplete or partial) information about the performance of algorithms on a set of training instances I_1, … , I_N ∈ℐ: where m_k'(I_n) is information about the performance (runtime) of algorithm A_k on the instance I_n. As already said, the overall loss of a model v on a dataset 𝒟 is a convex combination of a ranking and a regression loss:\",\n",
              "  'lsa_summary': ' Besides, precise numerical performance degrees are not always observable, for example when an algorithm is timed out, leading to missing or censored data in the case of regression, while preferences can still be derived. These considerations suggest that both aspects should be taken into account when training an algorithm selector: predicted runtimes should first of all match the order of algorithms, and if possible, even be close to the actually observed runtimes. The overall loss L_REG(𝒟,v) is then obtained by averaging (<ref>) over all N training instances. This loss corresponds to the negative log-likelihood of observing a pairwise preference under the Plackett-Luce (PL) model for ranking data <cit.>, which is commonly used in preference learning and label ranking <cit.>.',\n",
              "  'summary_BigBird': ['in this paper, we consider the problem of learning a regression model.<n> we introduce a new framework for learning a regression model.<n> we show that learning a regression model is in general not a ranking problem.<n> we also show that learning a regression model is in general not a ranking problem. <n> [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section '],\n",
              "  'summary_google_pegasus': ['In this paper, we present a new approach for training an algorithm selector (AS) that takes into account both the qualitative part of the training information, namely the order relations, and the loss of information, namely the actual runtimes achieved by the algorithms. Similar to the original combined regression and ranking approach presented by Sculley cit.>, our hybrid loss functions are based on a convex combination of a ranking term L_RANK that imposes ordering constraints between the individual predictions v_k(I), k  [K] 1,..., K, and a regression term L_REG that relates v_k to the actual runtime m(I,A_k) achieved by algorithm A_k'],\n",
              "  't5_summary': \"a hybrid loss function combines both aspects into a single criterion. the results are based on a convex combination of a ranking term v_k. a symmetric regression loss is a result of a 'non-symmetric' ranking loss. a symmetric regression loss is a result of a 'non-symmetric' ranking loss. a'sequence' of a'sequence' is a\"},\n",
              " 'Introduction': {'_text_': \"\\nAlgorithm selection (AS) refers to the task of automatically selecting an algorithm from a set of candidate algorithms, which appears to be most suitable for a given instance of a problem class. A typical application of AS is the selection of solvers for computationally hard problems on a per-instance basis. Prominent examples of such problems include the Boolean satisfiability problem (SAT) <cit.> and the travelling salesman problem (TSP) <cit.>.\\nDepending on the specific problem class, different criteria can be considered for assessing candidate algorithms. Especially important in this regard is an algorithm's efficiency measured in terms of its runtime.\\n\\nOn the basis of empirical runtime information, i.e., observations of runtimes on training instances, the AS problem is typically tackled by fitting regression functions, one per algorithm, to predict the runtime on new query instances <cit.>.\\nCollecting the predictions for all algorithms, the presumably fastest one is then selected.\\nRegression-based approaches proved to perform well in practice, often improving \\nover the algorithm that performs best on average, also known as the single best \\nsolver (SBS), by orders of magnitude <cit.>. \\n\\nIn spite of this practical success, one may wonder whether AS should indeed be tackled as a regression problem. First, since selection is eventually based on the comparison of the predicted runtimes, regression appears to be an unnecessarily difficult problem.\\nIndeed, prediction errors could be tolerated as long as they do not change the ranking of the algorithms, or even less, the presumably best algorithm. From this point of view, one may also question symmetric loss functions like the squared error loss, as commonly used in regression. For example, if algorithms A and B have runtimes of, respectively, 10 and 13 minutes, the estimates 12 and 11 minutes are clearly better than 5 and 9 minutes in terms of the squared error. However, whereas the former switch the order of the two algorithms, the latter will still promote the faster algorithm, namely A. \\n \\nThese considerations may suggest to tackle AS as a ranking instead of a regression problem, and indeed, ranking methods from the field of preference learning have  been used for constructing algorithm selectors <cit.>. Such models are learned from data comprised of problem instances together with respective rankings of the candidate algorithms. Data of that kind can often be collected more easily than precise numerical runtimes, which is another advantage of ranking methods. For example, if algorithm A finished before a given timeout is reached, while algorithm B did not, the preference A ≻ B can still be derived as training information, even if the concrete runtime of B is not known.\\n\\nHowever, the ranking-based approach could be criticized as well, namely for ignoring potentially useful training information about the actual runtimes, if available, and the performance margins between algorithms. For example, a runtime of 2 minutes for algorithm A and 2.1 minutes for B leads to the same ranking A ≻ B as a runtime of 2 minutes for A and 200 minutes for B.  \\n\\nIn this paper, we propose a hybrid approach to algorithm selection that combines both approaches, ranking and regression, hoping to benefit from the best of the two worlds: simplifying the learning task and solving the right problem while providing sufficiently detailed information such that concrete runtime information and margins between candidate algorithms are taken into account. To this end, we make use of hybrid loss functions <cit.>. Following a more formal description of the AS setting in the next section, our approach will be detailed in Sections 3 and 4. \\n\\nOur experimental evaluation in Section 5 confirms the potential of the proposed hybrid approach, which proves beneficial for several of the investigated scenarios. More specifically, optimizing our hybrid regression and ranking loss improves over optimizing the pure regression respectively ranking loss in terms of various metrics, eventually yielding a better performing algorithm selector.\\n\\n\",\n",
              "  'bart_summary': 'Algorithm selection (AS) refers to the task of automatically selecting an algorithm from a set of candidate algorithms. A typical application of AS is the selection of solvers for computationally hard problems on a per-instance basis. In this paper, we propose a hybrid approach to algorithm selection that combines both approaches, ranking and regression. We hope to benefit from the best of the two worlds: simplifying the learning task and solving the right problem while providing sufficiently detailed information such that concrete runtimes are taken into account.',\n",
              "  'gensim_summary': 'On the basis of empirical runtime information, i.e., observations of runtimes on training instances, the AS problem is typically tackled by fitting regression functions, one per algorithm, to predict the runtime on new query instances <cit.>.\\nFirst, since selection is eventually based on the comparison of the predicted runtimes, regression appears to be an unnecessarily difficult problem.\\nSuch models are learned from data comprised of problem instances together with respective rankings of the candidate algorithms.\\nHowever, the ranking-based approach could be criticized as well, namely for ignoring potentially useful training information about the actual runtimes, if available, and the performance margins between algorithms.\\nIn this paper, we propose a hybrid approach to algorithm selection that combines both approaches, ranking and regression, hoping to benefit from the best of the two worlds: simplifying the learning task and solving the right problem while providing sufficiently detailed information such that concrete runtime information and margins between candidate algorithms are taken into account.',\n",
              "  'lexrank_summary': ' Algorithm selection (AS) refers to the task of automatically selecting an algorithm from a set of candidate algorithms, which appears to be most suitable for a given instance of a problem class. On the basis of empirical runtime information, i.e., observations of runtimes on training instances, the AS problem is typically tackled by fitting regression functions, one per algorithm, to predict the runtime on new query instances <cit.>. For example, if algorithm A finished before a given timeout is reached, while algorithm B did not, the preference A ≻ B can still be derived as training information, even if the concrete runtime of B is not known. In this paper, we propose a hybrid approach to algorithm selection that combines both approaches, ranking and regression, hoping to benefit from the best of the two worlds: simplifying the learning task and solving the right problem while providing sufficiently detailed information such that concrete runtime information and margins between candidate algorithms are taken into account.',\n",
              "  'lsa_summary': ' Depending on the specific problem class, different criteria can be considered for assessing candidate algorithms. Regression-based approaches proved to perform well in practice, often improving over the algorithm that performs best on average, also known as the single best solver (SBS), by orders of magnitude <cit.>. These considerations may suggest to tackle AS as a ranking instead of a regression problem, and indeed, ranking methods from the field of preference learning have  been used for constructing algorithm selectors <cit.>. More specifically, optimizing our hybrid regression and ranking loss improves over optimizing the pure regression respectively ranking loss in terms of various metrics, eventually yielding a better performing algorithm selector.',\n",
              "  'summary_BigBird': ['we consider the problem of automatically selecting an algorithm from a set of algorithms, which is suitable for a given instance of the problem for a given class of candidate algorithms.<n> the problem of automatically selecting an algorithm from a set of algorithms, which is suitable for a given instance of the problem for a given class of candidate algorithms, is a typical example of computationally hard problems.<n> typical application of such selection solvers for such problem include the problem of automatically selecting an algorithm from a set of algorithms, which is suitable for a given instance of the problem for a given class of candidate algorithms. in this paper, we consider the problem of automatically selecting an algorithm from a set of algorithms, which is suitable for a'],\n",
              "  'summary_google_pegasus': ['In this paper, we present a novel method for selecting the fastest algorithm for a computationally hard problem, using a regression-based approach, and discuss its potential use as a ranking method for other computationally hard problems, such as those dealing with Boolean satisfiability and the travelling salesman problem, both of which are discussed in more detail in our previous papers.., et al., International Conference on Machine Learning (ICML) 2007), Springer, Berlin, Germany, 26-30 June, 2007.'],\n",
              "  't5_summary': 'algorithm selection (AS) is based on the comparison of predicted runtimes. the algorithm is typically tackled by fitting regression functions, one per algorithm, to predict the runtime on new query instances cit.. a hybrid approach to algorithm selection is proposed to simplify the learning task and solve the right problem. a hybrid approach to algorithm selection is proposed to be detailed in sections 3 and 4. a hybrid approach to algorithm selection is proposed to be used to simplify the learning task and solve the right problem.'},\n",
              " 'Models and Optimization': {'_text_': \"\\n\\nFor modeling the scoring functions v_k ℐ→ℝ, we consider three types of models, namely linear models, quadratic models, and feed-forward neural networks. Linear models define the score of an algorithm A_k ∈𝒜 for a specific problem instance I ∈ℐ in terms of a linear combination of the instance features:\\n\\n    \\n\\nwhere w_k ∈ℝ^d are the model parameters. To model quadratic relationships, a polynomial feature transformation ϕℝ^d →ℝ^d(d+1)/2 is applied that maps the instance features to all monomials of degree 2. Consequently, the quadratic models are described by weight vectors w_k ∈ℝ^d(d+1)/2. We summarize all  model parameters in a single parameter set W = {w_k   |   A_k ∈𝒜}. Since all loss terms are convex, their convex combination (<ref>) remains convex, and their minimization can be accomplished using gradient-based optimization methods. We apply the L-BFGS-B algorithm <cit.> for this task. To avoid overfitting, we employ weight decay by adding a regularization term R(W) = γ∑_k=1^K∑_j=1^d [w_k]_j^2, which can be adjusted by setting γ∈ℝ to an appropriate value.\\n\\nThe neural network is given by a simple feed-forward architecture as illustrated in Figure <ref>.\\n\\nWe adapt the training procedure from <cit.> for our setting of hybrid ranking and regression. For adjusting the model's weights W, backpropagation is applied.\\nThe Adam optimizer <cit.> was selected as a gradient-based optimization method for minimizing the loss function. Regularization is implemented in terms of early stopping. Before the training procedure starts, a fraction of the original training dataset is selected as a validation set and removed from the training data. During the training, the model's loss on this validation set is computed periodically. A rising validation loss is an indicator of overfitting, thus the training procedure is stopped if an increase in the validation loss is observed for several consecutive checks. Afterwards, the model parameters are fixed to the set of weights that achieved the best validation loss during training.\\n\\n\\n\",\n",
              "  'bart_summary': \"We consider three types of models, namely linear models, quadratic models, and feed-forward neural networks. Linear models define the score of an algorithm for a specific problem instance I  in terms of a linear combination of the instance features. We employ weight decay by adding a regularization term R(W) to avoid overfitting. For adjusting the model's weights W, backpropagation is applied. We adapt the training procedure from <cit.> for our setting of hybrid ranking and regression.\",\n",
              "  'gensim_summary': 'Since all loss terms are convex, their convex combination (<ref>) remains convex, and their minimization can be accomplished using gradient-based optimization methods.\\nTo avoid overfitting, we employ weight decay by adding a regularization term R(W) = γ∑_k=1^K∑_j=1^d [w_k]_j^2, which can be adjusted by setting γ∈ℝ to an appropriate value.\\nAfterwards, the model parameters are fixed to the set of weights that achieved the best validation loss during training.',\n",
              "  'lexrank_summary': ' For modeling the scoring functions v_k ℐ→ℝ, we consider three types of models, namely linear models, quadratic models, and feed-forward neural networks. Linear models define the score of an algorithm A_k ∈𝒜 for a specific problem instance I ∈ℐ in terms of a linear combination of the instance features: Before the training procedure starts, a fraction of the original training dataset is selected as a validation set and removed from the training data. Afterwards, the model parameters are fixed to the set of weights that achieved the best validation loss during training.',\n",
              "  'lsa_summary': ' We summarize all  model parameters in a single parameter set W = {w_k   |   A_k ∈𝒜}. To avoid overfitting, we employ weight decay by adding a regularization term R(W) = γ∑_k=1^K∑_j=1^d [w_k]_j^2, which can be adjusted by setting γ∈ℝ to an appropriate value. The neural network is given by a simple feed-forward architecture as illustrated in Figure <ref>. We adapt the training procedure from <cit.> for our setting of hybrid ranking and regression.',\n",
              "  'summary_BigBird': ['in this paper, we consider the problem of selecting the best subset of parameters to model a given function.<n> we consider three types of models, namely linear models, namely linear models, and neural networks, models define score of the function.<n> we consider the problem of selecting the best subset of parameters to model a given function.<n> we consider three types of models, namely linear models, namely linear models, and neural networks, models define score of the function. <n> we consider the problem of selecting the best subset of parameters to model a given function.<n> we consider three types of models, namely linear models, namely linear models, and neural networks '],\n",
              "  'summary_google_pegasus': ['In this paper, we present a novel method for training and validation of weight-fitting models for the best scoring functions of v_k IR and v_k IR for the best scoring functions of v_k IR and v_k IR for the best scoring functions of v_k IR and v_k IR for the best scoring functions of v_k IR and v_k IR for the best scoring functions of v_k IR and v_k IR for the best scoring functions of v_k IR and v_k IR for the best scoring functions of v_k IR and v_k'],\n",
              "  't5_summary': 'linear models define the score of an algorithm A_k A for a specific problem instance I I. a polynomial feature transformation Rd Rd(d+1)/2 is applied. to avoid overfitting, we employ weight decay by adding a regularization term R(W) = _k=1K_j=1d [w_k]_j2.'}}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_latext_file2 = \"/content/drive/MyDrive/TextSummarizationResults/Paper2/main.tex\""
      ],
      "metadata": {
        "id": "ulD92kLg_JkP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_latext_file3 = \"/content/drive/MyDrive/TextSummarizationResults/Paper3/sbse_paper.tex\""
      ],
      "metadata": {
        "id": "7dGR3KJwRw28"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YICEdieGMvOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def latex_parser_summarizer(file_path):\n",
        "  latex_text_parser = LatexTextParser(file_path)\n",
        "  section_content_file, abstract_file, section_names_file = latex_text_parser.latex_text_parser()\n",
        "  text_summary_dict = dict()\n",
        "  for sections in section_names_file:\n",
        "    text_summary_dict[sections] = textSummarizer.text_summarizer(section_content_file[sections],100,150,4)\n",
        "  return text_summary_dict\n",
        "\n"
      ],
      "metadata": {
        "id": "631kEByoIpbm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_summary_dict_file2 = latex_parser_summarizer(file_path_latext_file2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFlmLdn8Me9r",
        "outputId": "1426212f-fdaf-4228-fb83-470ce7136a57"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['we propose to tackle the runtime problem ( cit.  ) cit.  ) cit.  ] we propose to tackle the runtime problem ( cit.  ) cit.  ] we propose to tackle the runtime problem ( cit.  ) cit.  ] we propose to tackle the runtime problem ( cit.  ) cit.  ] we propose to tackle the runtime problem ( cit.  ) cit.  ']\n",
            "['in this paper, we consider the problem of recommendation of a set of surrogates, where the surrogates are assumed to be pre- and/or post - selected from a given set.<n> we consider the problem of finding a pre- or post - selected set of surrogates, where the surrogates are assumed to be pre- or post - selected from a given set.<n> we consider the problem of finding a pre- or post - selected set of surrogates, where the surrogates are assumed to be pre- or post - selected from a given set.<n> we consider the problem of finding a pre- or post - selected set of surrogates, where the surrogates are assumed to be']\n",
            "['in this paper, we study the problem of learning a regression model for a given data set.<n> we consider the case when the learning process is a priori known to the learner, and the case when the learning process is not a priori known. <n> [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ]']\n",
            "['we present an experimental evaluation of the proposed superset learning approach. <n> [ [ section ] ] the experimental evaluation of the proposed superset learning approach. <n> [ [ section ] ] the experimental evaluation of the proposed superset learning approach. <n> [ [ section ] ] the experimental evaluation of the proposed superset learning approach. <n> [ [ section ] ] the experimental evaluation of the proposed superset learning approach. <n> [ [ section ] ] the experimental evaluation of the proposed superset learning approach. <n> [ [ section ] ] the experimental evaluation of the proposed superset learning approach. <n> [ [ section ] ]']\n",
            "['this paper, we proposed to consider algorithm selection within the framework of superset learning within the framework of superset learning to censored data in a way in which the algorithm selection within the framework of superset learning within the framework of superset learning to censored data in a way in which the algorithm selection within the framework of superset learning to censored data in a way in which the algorithm selection within the framework of superset learning to censored data in a way in which the algorithm selection within the framework of superset learning to censored data in a way in which the algorithm selection within the framework of superset learning to censored data in a way in which the algorithm selection within the framework of superset learning to censored data in a way in which the algorithm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_summary_dict_file3 = latex_parser_summarizer(file_path_latext_file3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKBMKb5gMtOB",
        "outputId": "17bf3665-d3ea-4e43-ea96-fc5f91d05b51"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['in this paper, we propose a method of testing for optimal solutions of search-based optimization problems.<n> the method of testing for optimal solutions of search-based optimization problems is based on a fitness function.<n> the method of testing for optimal solutions of search-based optimization problems is based on a fitness function. <n> [ [ section ] ] in this paper, we propose a method of testing for optimal solutions of search-based optimization problems.<n> the method of testing for optimal solutions of search-based optimization problems is based on a fitness function. <n> [ [ section ] ] in this paper, we propose a method of testing for optimal solutions of search-based optimization problems ']\n",
            "[\"in this paper, we study the problem of finding an optimal solution to the equation :  what is the temperature of the solution? ''.<n> we consider the problem of finding an optimal solution to the equation :  what is the temperature of the solution? ''.<n> we study the problem of finding an optimal solution to the equation :  what is the temperature of the solution? ''. in this paper, we study the problem of finding an optimal solution to the equation :  what is the temperature of the solution? ''. we consider the problem of finding an optimal solution to the equation :  what is the temperature of the solution?\"]\n",
            "['in this paper, we prove that : ( i ) it is np - complete to determine if a given set of parameters can be tested faster than a given set of other parameters ; ( ii ) it is np - complete to determine if a given set of parameters can be tested faster than a given set of other parameters ; ( iii ) it is np - complete to determine if a given set of parameters can be tested faster than a given set of other parameters ; ( iv ) it is np - complete to determine if a given set of parameters can be tested faster than a given set of other parameters ; ( v ) it is np - complete to determine if a given']\n",
            "['in this paper we show that the problem of finding an optimal code generation solution for a given problem can be reduced to the problem of finding an optimal solution for a given set of inputs. <n> the problem of finding an optimal code generation solution for a given problem can be reduced to the problem of finding an optimal solution for a given set of inputs. <n> the problem of finding an optimal code generation solution for a given problem can be reduced to the problem of finding an optimal solution for a given set of inputs. <n> the problem of finding an optimal code generation solution for a given problem can be reduced to the problem of finding an optimal solution for a given set of inputs. <n> the problem of finding an optimal code']\n",
            "['the field of software engineering ( sse ) is widely research areas. the field of software engineering ( sse ) is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Dumping the result into json files\n",
        "save_file_path = r\"/content/drive/MyDrive/TextSummarizationResults/summary_section_results_sbse.json\"\n",
        "import json\n",
        "with open(save_file_path, 'w') as fp:\n",
        "    json.dump(text_summary_dict_file3, fp, indent=4)"
      ],
      "metadata": {
        "id": "DOPsIkY0R9X7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Dumping the result into json files\n",
        "save_file_path = r\"/content/drive/MyDrive/TextSummarizationResults/summary_section_results_file2.json\"\n",
        "import json\n",
        "with open(save_file_path, 'w') as fp:\n",
        "    json.dump(text_summary_dict_file2, fp, indent=4)"
      ],
      "metadata": {
        "id": "EmOc_bjtUAek"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_summary_dict_file3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjGPFn1CUK9Z",
        "outputId": "cef1c3b3-158b-4f03-8b8b-1a861fe19e73"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Analysis of techniques and applications of SBSE in Testing ': {'_text_': \"\\nThis section provides an analysis between different activities of testing in which search based optimization is used and search techniques used in those areas.\\nA wide range of search techniques is used in search-based software engineering to find an optimal solution. \\nFigure 6 shows distributions of SBSE papers on different search-based optimization techniques applied in SBSE. In this figure, the stacked bar ‘EAs’ represents the class of all Evolutionary Algorithms. Evolutionary algorithms are derived from  Darwinian principle <cit.> of evolution in Biology. Genetic algorithm and the genetic program are frequently used evaluation algorithms. Genetic algorithm is already described in section 2.3 of this paper. Genetic programming <cit.> is a variant of Genetic algorithm in which members of the population is an abstract syntax tree of a simple program instead of list <cit.>. \\n\\n\\nThe top portion of bar labelled ‘EAs*’ refers to the proportion of the literature's where authors have only stated that evolution algorithm used for the problems. However, authors have not specified particularly which evolution algorithm is used to solve the problem <cit.>. \\n\\n\\nThere has been a significant increase in the popularity of using an evolutionary algorithm for search-based optimization in the last fifteen years. It can be noticed from the graph that next frequently used algorithms after evolutionary algorithms are Hill climbing (HC) and Simulated Annealing (SA).\\n\\nIt can be noticed from the graph that some other search techniques such as Ant Colony Optimization (ACO), Greedy Search (GS), Integer Programming (IP), Tabu Search(TS), Artificial Immune System (AIS), Memetic Algorithm, Sequence Quadratic Programming  ( SQP ) are applied to small portion of papers on SBSE. However focus of this paper on Hill Climbing(HC), Simulated Annealing (SA) and  Genetic Algorithms (GA), Genetic Programming(GP)  commonly used techniques in SBSE.\\n\\nHill-climbing does not guarantee to find a globally optimal solution besides that it is comparatively used in many areas of software engineering. The intuition behind that is hill climbing is easy to implement and fast in execution <cit.>. Hill climbing able to find merely ‘good\\nenough’ <cit.>  solution which is sufficiently better than the current solution. Simulated annealing is slightly better than hill climbing as it tries to avoid local optima by initially keeping temperature high which causes solution space to explore more. Genetic algorithms nowadays gaining high popularity for search-based optimization problems as they can avoid local optimal and operate with more solutions at a time. \\n\\nTable 1 illustrates papers of SBSE is testing with search technique and fitness function used for that application area in the testing <cit.>. This analysis is prepared by referring to the paper <cit.>, providing a comprehensive analysis of techniques and applications of SBSE. This analysis focuses on some of the key areas of software testing. The analysis centres on commonly used meta-heuristic techniques discussed in section 2 of this paper.  For some papers displayed in the paper, authors have not mentioned particularly which evolutionary algorithm used to address the paper. Such papers are labelled with EAs in the table.\\n\\nThe table starts with the very first publication in SBSE by Miller and Spooner <cit.> in 1976 which was for the generations of test data for floating-point inputs with the goal of higher test coverage. Integer programming techniques were used at that time  <cit.>. However, after than many papers are published for test data generation using various criteria for fitness functions and different search-based optimization techniques as shown in the table. Schoenauer and Xanthakis proposed the <cit.> the approach of test data generation using Genetic algorithm in structural testing. It was the first attempt using Genetic algorithm. After that used of Genetic algorithm for solving software engineering problems has increased significantly <cit.>. It can be noticed from the table that most of the fitness functions target various code coverage criteria and fault detection. \\n\\nL[1]>p#1\\n|L2.3cm|L3.5cm|L4cm|L2cm|\\nSBSE papers on testing for different activities, objectives and search techniques used for approaches <cit.>  \\n\\nAuthors[Ref]     Activity in Testing     Objective / Fitness     Search Techniques \\n 4c\\n  – continued from previous page \\n\\nAuthors[Ref]     Activity in Testing     Objective / Fitness     Search Techniques \\n 4|r|Continued on next page \\n Miller and Spooner <cit.>      Test data generation for floating point input     Maximize  Test Coverage     Integer Programming \\n Schoenauer and Xanthakis  <cit.>      Test data generation     Maximize coverage of selected substructure     GA\\n Schultz et al. <cit.>    Test scenario generation     Identify maximum faults     GA\\n Baradhi and Mansour <cit.>     Comparative study of regression testing algorithms     Minimize execution time and the number of test cases, Maximize the Precision     GA,SA\\n Jones et al.<cit.>     Branch and fault-based testing     Maximize branch coverage and fault detection     GA\\n Sthamer<cit.>      Test data generation     Maximize  Branch Coverage     GA \\n Roper <cit.>     Test data generation     Maximize   code coverage     GA \\n Alander et al.<cit.>     Test case generation     Minimize the response time     GA \\n Pohlheim and Wegener <cit.>     Verifying worst/best case execution time      Optimize worst/best case execution     GA\\n Li and Wu <cit.>     Software test automation      Minimal multiple-condition coverage test     EAs\\n Cohen et al. <cit.>     Test suites generation     Maximize code coverage     SA \\n Ghazi and Ahmed <cit.>     Interaction testing     Maximize pairwise test coverage     GA\\n Baresel et al.<cit.>    Automatic sequence testing     Maximize structural coverage      EA\\n Garousi <cit.>     Test data generation in stress  testing     Maximize the traffic on a specified network or node    GA\\n Cohen et al.<cit.>     Interaction Testing     Maximize pair-wise and t-way     HC,SA\\n Walcott et al. <cit.>     Regression test suite prioritization     Maximize code coverage     GA\\n Groß and Mayer <cit.>     Component testing of real- time systems     Maximize worst-case execution time     GA\\n Watkins et al. <cit.>     Test suites generation     Detect the system failures     GA \\n Arcuri and Yao<cit.>     Test data   generation for Java Containers     Maximize code coverage; Minimize input sequence length     HC, SA,GA \\n Li et al.<cit.>     Regression test  case prioritization     Maximize block coverage     HC, GA \\nDi Penta et al.<cit.>      Test inputs generation and configurations     Maximize code coverage     GA,Random Search \\n Wappler   and Wegener<cit.>     Test case generation for unit testing of OO software     Maximize branch coverage using three distance metrics     GP \\n Arcuri and Yao <cit.>     Automatic bug fixing     Distance function     GP \\n Bueno et al.<cit.>     Automatic Test Data Generation Using Particle Systems     Optimize the diversity among the test data on a test data set Simulated Repulsion     GA, SA \\n Buehler and Wegener <cit.>     Functional testing     Automatic finding faults     GA \\n \\n\\n\\n\\n\",\n",
              "  'bart_summary': 'A wide range of search techniques is used in search-based software engineering to find an optimal solution. This section provides an analysis between different activities of testing in which search based optimization is used and search techniques used in those areas. The analysis centres on commonly used meta-heuristic techniques discussed in section 2 of this paper. The table starts with the very first publication in SBSE by Miller and Spooner <cit.> in 1976 which was for the generations of test data for floating-point inputs with the goal of higher test coverage.',\n",
              "  'gensim_summary': 'This section provides an analysis between different activities of testing in which search based optimization is used and search techniques used in those areas.\\nIt can be noticed from the graph that some other search techniques such as Ant Colony Optimization (ACO), Greedy Search (GS), Integer Programming (IP), Tabu Search(TS), Artificial Immune System (AIS), Memetic Algorithm, Sequence Quadratic Programming  ( SQP ) are applied to small portion of papers on SBSE.\\nHowever focus of this paper on Hill Climbing(HC), Simulated Annealing (SA) and  Genetic Algorithms (GA), Genetic Programming(GP)  commonly used techniques in SBSE.\\nGenetic algorithms nowadays gaining high popularity for search-based optimization problems as they can avoid local optimal and operate with more solutions at a time.\\nTable 1 illustrates papers of SBSE is testing with search technique and fitness function used for that application area in the testing <cit.>.\\nThe table starts with the very first publication in SBSE by Miller and Spooner <cit.> in 1976 which was for the generations of test data for floating-point inputs with the goal of higher test coverage.\\nHowever, after than many papers are published for test data generation using various criteria for fitness functions and different search-based optimization techniques as shown in the table.\\nSBSE papers on testing for different activities, objectives and search techniques used for approaches <cit.>  \\nMiller and Spooner <cit.>      Test data generation for floating point input     Maximize  Test Coverage     Integer Programming \\nRoper <cit.>     Test data generation     Maximize   code coverage     GA \\n<cit.>     Test suites generation     Maximize code coverage     SA \\nArcuri and Yao<cit.>     Test data   generation for Java Containers     Maximize code coverage; Minimize input sequence length     HC, SA,GA \\nDi Penta et al.<cit.>      Test inputs generation and configurations     Maximize code coverage     GA,Random Search ',\n",
              "  'lexrank_summary': ' This section provides an analysis between different activities of testing in which search based optimization is used and search techniques used in those areas. Genetic algorithm and the genetic program are frequently used evaluation algorithms. However focus of this paper on Hill Climbing(HC), Simulated Annealing (SA) and  Genetic Algorithms (GA), Genetic Programming(GP)  commonly used techniques in SBSE. However, after than many papers are published for test data generation using various criteria for fitness functions and different search-based optimization techniques as shown in the table.',\n",
              "  'lsa_summary': ' A wide range of search techniques is used in search-based software engineering to find an optimal solution. However, authors have not specified particularly which evolution algorithm is used to solve the problem <cit.>. Hill-climbing does not guarantee to find a globally optimal solution besides that it is comparatively used in many areas of software engineering. Genetic algorithms nowadays gaining high popularity for search-based optimization problems as they can avoid local optimal and operate with more solutions at a time.',\n",
              "  'summary_BigBird': ['in this paper we show that the problem of finding an optimal code generation solution for a given problem can be reduced to the problem of finding an optimal solution for a given set of inputs. <n> the problem of finding an optimal code generation solution for a given problem can be reduced to the problem of finding an optimal solution for a given set of inputs. <n> the problem of finding an optimal code generation solution for a given problem can be reduced to the problem of finding an optimal solution for a given set of inputs. <n> the problem of finding an optimal code generation solution for a given problem can be reduced to the problem of finding an optimal solution for a given set of inputs. <n> the problem of finding an optimal code'],\n",
              "  'summary_google_pegasus': ['Search-based software engineering (SBSE) is a branch of software engineering which aims to improve the performance of software by using search-based optimization techniques to find an optimal solution to a problem. However focus of this paper on Hill Climbing(HC), Simulated Annealing (SA) and Genetic Algorithms (GA), Genetic Programming(GP) commonly used techniques in SBSE. The aim of this paper is to provide an analysis between different activities of testing in which search based optimization is used and search techniques used in those areas.'],\n",
              "  't5_summary': \"stacked bar ‘EAs’ represents the class of all evolutionary algorithms. the stacked bar ‘EAs’ represents the class of all evolutionary algorithms. the genetic program is frequently used evaluation algorithms. the top portion of bar labelled ‘EAs*’ refers to the proportion of the literature's where authors have only stated that evolution algorithm used for the problems cit.>. the paper focuses on some of the key areas of software testing.\"},\n",
              " 'Application areas of SBSE in Testing': {'_text_': '\\nSBSE is used throughout all stages of software engineering life-cycle. As it is shown earlier in figure 2, the highest proportion of the papers in SBSE are regarding testing. majority of contribution (54 %) in search-based software engineering belongs to the testing domain of software engineering.\\n\\nTest data can be expressed easily using two key indicators of SBSE (Shown in Figure 1): Representation of problem and Fitness Function<cit.>. Test data are generally well defined such as test cases, input Vectors, sequences of input to the test <cit.>. So, a suitable representation of the problem for testing is available.  Test goals can be expressed as a fitness function to find the optimal solution <cit.>. The generic nature of the solution makes it easier by changing the input space and fitness function, the approach can be adapted to different testing problems <cit.>.So it can be stated that SBSE is well adapted for the testing problems.  \\n\\n\\n\\nFigure 4 lists the publications of SBSE in the domain of the software testing from 1976 to 2011 <cit.>. The first contribution in search-based optimization was in software testing by two American researchers, Webb Miller and David Spooner in 1976 <cit.>. They proposed a method for test data generation consists of floating-point inputs. \\n\\n After the use of meta-heuristic techniques popularity for search-based optimization problems has increased drastically. They have been applied to the different aspects of testing problems, including functional testing, temporal testing, integration testing, regression testing, stress testing, mutation testing, test prioritization, interaction testing, state machine testing and exception testing <cit.>. The figure shows the explosion of interest in publications in Search-Based Software testing from 1976 till 2011 <cit.>. This section provides a brief overview of key areas in software testing to which search-based optimization techniques have been applied.\\n\\n\\n §.§ Regression Testing\\n \\nRegression testing is a type of software testing performed to check if a recent modification in program or code change has not adversely affected the existing functionality of the system   <cit.>. Regression testing is generally performed on the following circumstances: after bug fixing,  addition or modification of system functionality, changes in requirements. One of the simplest ways to perform regression testing is \\' re-test all method \\'  <cit.>. In this approach, all tests available in the test suites are executed again on the system. However, it is not feasible in terms of time and resources costs while executing all of the test cases again.\\n\\nTest case prioritization problem is defined below <cit.>. Function f mapped the set of all permutation for regression test suite TP to the real number  ℝ. Here, ℝ  refer as fault detection capability based on how earlier it can uncover the faults or faults known after the execution of test case <cit.>. Problem is to find the permutations of test suite T from the set which has earlier fault detection capability.  \\n Test Case Prioritization (TCP) problem representation<cit.>Given: A test suite, T , the set of permutations of Test suite T : PT , and a function from PT to real numbers,\\nf : PT → ℝ\\nProblem: to find T\\' ∈ PT  such that (∀ T”)(T”≠ T\\')[ f(T\\') ≥ f(T”)]\\n\\n Since the execution of all test cases again is expensive, test case prioritization technique works on the idea that more important tests should be executed earlier. Important tests in case of regressions are which can detect the faults earlier  <cit.>. Here, the objective of the test is to \" maximize earlier fault detection rate <cit.>.\" \\n Test case prioritization(TCP)<cit.> problem can be solved by reformulating it as a search problem with optimization in test suites permutations. The set of all possible candidate solutions is the set of all possible permutations of tests in the regression test suite. The set of candidate solution for the search problem will be all permutation of the tests in the regression test suite.  Fitness function can be design for the test case prioritization by evaluating quality on software metric. Software metric used for TCP problem is “Average number of faults detection (APFD)”<cit.>. Higher APFD value leads to higher fitness value for a given solution which suggests that faults are detected earlier in testing.The problem can be solved using any meta-heuristic techniques discussed earlier hill climbing and genetic algorithm <cit.>.  If hill climbing is used for solving the problem, a set of the neighbouring solution needs to be defined. Otherwise, if the Genetic algorithm is used for problem-solving then set of simple genetic operators need to be defined for the search problem. \\n\\n\\n §.§ Structural Testing\\n\\nStructural testing is one of the types of white-box software testing performed to test the structure of the code. Structural testing can be performed on the software based on the different coverage criteria. Structural testing uses a control graph which shows the graphical representation of the code. There are basically 3 coverage criteria for structural testing: \\n\\n\\n  * Statement coverage: test all the statements in the program with a number of executed statements.\\n\\n  * Branch coverage: Test all branches available in control flow graph at a decision point with a number of branches executed. \\n\\n  * Path coverage: Test the executed paths in control flow graph from start to end of the program with all paths of the program.\\n\\n Structural testing is one of the popular application areas of SBSE in Testing. Structural testing was also the first area considered using meta-heuristic search techniques by Xanthakis et al. <cit.> in 1992  <cit.>.  Compare with other criteria branch coverage is commonly considered the area on structural testing <cit.>. The goal for early works was to maximize branch coverage. So problem representation for the search problem was the test suite and objective of fitness function objective was  \\' maximize overall branch coverage <cit.>. Later works evolved and the aim was shifted to view each branch as a test objective. Fitness functions were designed based on the path taken by a test case <cit.>\\'.  There also has been work regarding data flow coverage for example, by Girgis using genetic algorithm <cit.>. After 1995 works in structural testing have increased significantly. Table 1 provides an analysis of some papers published on test data generation using various structural criteria for the fitness functions.    \\n\\n\\n\\n §.§ Temporal Testing\\n\\nTemporal testing involves finding best-case and worst-case execution time of the system component <cit.>. One approach to deal with this is using static analysis. However, the approximations made by static analysis are often not precise<cit.>. These approximations are often over-approximations in the case of worst-case execution time, and\\nunder-approximations in the case of best-case and worst-case execution time <cit.>. The only actual execution of the software can reveal concrete times <cit.>.\\n\\nThis problem can be solved by the reformulation of the problem as a search problem. Search tries to find accurate execution time of given input <cit.>. Fitness function for search is the execution time of the given input and search tries to minimize it in case of best-case execution time and maximize it in case of worst-case execution time <cit.>. Commonly Search techniques used for measuring accurate time is Genetic algorithm <cit.>.\\nAn approach of SBSE can reveal conservative lower bound in case of best-case execution time and upper bound for worst-case execution. A real-time application of the use of this approach is in Temporal testing in an air-bag controller <cit.> which monitors the deceleration profile of a car and decide when to launch the airbag <cit.>. If the airbag is released too\\nearly, the action may be premature, while releasing the airbag too late may prove fatal to the driver <cit.>. \\n\\n\\n\\n\\n §.§ Functional Testing\\n\\nFunctional  Testing is a type of black-box testing performed to check the functional requirements of the system or system component.\\nOne of the famous application of SBSE in the functional testing is in the car parking controller of  Daimler Chrysler <cit.>. Here, the task of the car parking controller is to identify a suitable parking space for car and then automatically driving the car into that space without colliding with any other objects <cit.>. One possibility is to do manual testing of the complete system. However, manual testing is costly and time-consuming <cit.>.\\n\\nHere, using approach of SBSE, automated testing can be performed on the controller to test for a large number of test cases <cit.>. Fitness function for search could be the shortest distance to a point of a collision while parking a car <cit.>. The objective of the search would then be to minimize the distance in order to test cover every faulty situation of the controller. The problem can be solved using the meta-heuristic technique, genetic algorithm. So search used generated parking scenarios of the controller, which were then\\nautomated using the controller, and the closest distance to a\\ncollision recorded through the simulation to obtain a fitness\\nvalue <cit.>.\\n\\n\\n §.§ Automatic Test Data Generation\\n\\nMost of the work on Software testing is concerning to the problem of generating inputs that build a test suite that meets \\' a test adequacy criterion \\' <cit.>. Without automation, the process is slow, expensive and error-prone. search-based software engineering (SBSE) can be used to automate test data generation <cit.>. metaheuristic search techniques can be applied to automate test data generation for structural and\\nfunctional testing <cit.>. Here, different fitness function could be employed based on the problem requirements. It could be maximized path coverage, maximize code coverage, minimize response time. The table in section 5 lists some papers with a different objective for fitness function for automatic test data generations.\\n \\n',\n",
              "  'bart_summary': 'SBSE is used throughout all stages of software engineering life-cycle. The majority of contribution (54%) in search-based software engineering belongs to the testing domain ofSoftware engineering. SBSE can be expressed easily using two key indicators: Representation of problem and Fitness Function. After the use of meta-heuristic techniques popularity for search- based optimization problems has increased drastically. They have been applied to the different aspects of testing problems, including functional testing, temporal testing, integration testing, regression testing, stress testing and mutation testing.',\n",
              "  'gensim_summary': \"Test data can be expressed easily using two key indicators of SBSE (Shown in Figure 1): Representation of problem and Fitness Function<cit.>.\\nThe generic nature of the solution makes it easier by changing the input space and fitness function, the approach can be adapted to different testing problems <cit.>.So it can be stated that SBSE is well adapted for the testing problems.\\nThis section provides a brief overview of key areas in software testing to which search-based optimization techniques have been applied.\\nFunction f mapped the set of all permutation for regression test suite TP to the real number  ℝ.\\nProblem is to find the permutations of test suite T from the set which has earlier fault detection capability.\\nTest Case Prioritization (TCP) problem representation<cit.>Given: A test suite, T , the set of permutations of Test suite T : PT , and a function from PT to real numbers,\\nTest case prioritization(TCP)<cit.> problem can be solved by reformulating it as a search problem with optimization in test suites permutations.\\nThe set of candidate solution for the search problem will be all permutation of the tests in the regression test suite.\\nFitness function can be design for the test case prioritization by evaluating quality on software metric.\\nHigher APFD value leads to higher fitness value for a given solution which suggests that faults are detected earlier in testing.The problem can be solved using any meta-heuristic techniques discussed earlier hill climbing and genetic algorithm <cit.>.\\nStructural testing can be performed on the software based on the different coverage criteria.\\n* Branch coverage: Test all branches available in control flow graph at a decision point with a number of branches executed.\\nSo problem representation for the search problem was the test suite and objective of fitness function objective was  ' maximize overall branch coverage <cit.>.\\nFitness functions were designed based on the path taken by a test case <cit.>'.\\nTable 1 provides an analysis of some papers published on test data generation using various structural criteria for the fitness functions.\\nsearch-based software engineering (SBSE) can be used to automate test data generation <cit.>.\\nmetaheuristic search techniques can be applied to automate test data generation for structural and\\nThe table in section 5 lists some papers with a different objective for fitness function for automatic test data generations.\",\n",
              "  'lexrank_summary': \" Since the execution of all test cases again is expensive, test case prioritization technique works on the idea that more important tests should be executed earlier. So problem representation for the search problem was the test suite and objective of fitness function objective was  ' maximize overall branch coverage <cit.>. Fitness function for search is the execution time of the given input and search tries to minimize it in case of best-case execution time and maximize it in case of worst-case execution time <cit.>. Here, using approach of SBSE, automated testing can be performed on the controller to test for a large number of test cases <cit.>.\",\n",
              "  'lsa_summary': ' This section provides a brief overview of key areas in software testing to which search-based optimization techniques have been applied. Regression testing is generally performed on the following circumstances: after bug fixing,  addition or modification of system functionality, changes in requirements. Later works evolved and the aim was shifted to view each branch as a test objective. Table 1 provides an analysis of some papers published on test data generation using various structural criteria for the fitness functions.',\n",
              "  'summary_BigBird': ['in this paper, we prove that : ( i ) it is np - complete to determine if a given set of parameters can be tested faster than a given set of other parameters ; ( ii ) it is np - complete to determine if a given set of parameters can be tested faster than a given set of other parameters ; ( iii ) it is np - complete to determine if a given set of parameters can be tested faster than a given set of other parameters ; ( iv ) it is np - complete to determine if a given set of parameters can be tested faster than a given set of other parameters ; ( v ) it is np - complete to determine if a given'],\n",
              "  'summary_google_pegasus': ['Search-based software engineering (SBSE) is a branch of software engineering which deals with the problem of finding the optimal solution to a particular problem in a given software package, program or set of software packages by means of search engines such as Google, Bing, Yahoo, etc., or by means of programming languages such as C, Java, Python, Ruby, etc., or by means of programming languages such as C, Java, Ruby, Python, or by means of programming languages such as C, Java, Ruby, Python, or by means of programming languages such as C, Java, Ruby, Python, or by means of programming languages such as C, Java, Ruby, Python, or by means of programming languages such'],\n",
              "  't5_summary': 'most of the papers in SBSE are regarding testing. most of the papers in the software engineering are regarding testing. a majority of the papers in SBSE are regarding testing. the majority of contributions (54 %) are regarding testing. the majority of the papers in SBSE belong to the testing domain. the first contribution in search-based optimization was in 1976 cit. the first contribution in search-based optimization was in software testing by two american researchers, Webb Miller and David Spooner.'},\n",
              " 'Conclusion': {'_text_': \"\\nSearch-based software engineering is the emerging field of software engineering which uses meta-heuristic techniques to tackle the problems of software engineering. Search-based software engineering reformulates the problem of software engineering as 'computational search problems' in order to find an optimal or near-optimal solution for the search problems. Search based software engineering reformulates various problems in software engineering to search problem with the help of two indicators: Problem representation and fitness function <cit.>. Fitness function distinguish between solutions and direct search to find an optimal solution.  This paper discusses the most popular meta-heuristics techniques applied in search-based software engineering (SBSE): Hill Climbing, simulated annealing, genetic algorithm.  SBSE has been applied to different fields of software engineering. Testing is widely research areas of SBSE. This paper focuses on the popular application areas of SBSE in testing. This paper provides an analysis between different application areas in which search-based optimization has applied and techniques used for those areas. The most considered search techniques in SBSE is a Genetic Algorithm. are genetic algorithms This analysis can be helpful in future for researchers in the field of SBSE to get an impression about which search techniques are used to address the different problem in software testing. \\n\\n\\n\\n\\nPseudo code for Argumentativeness computation for a sentence s_i in hybrid approach   \\n \\nargumentative score = Argumentative Sentence Classifier(s_i)\\nargumentative score >= 0.5  \\nclaim probability score  = Claim Classifier(s_i)\\nargumentativeness = 0.5 * (argumentative score + claim probability score)\\nargumentativeness = argumentative score\\n\\n\\n\\n\\n\\n\\nplain\\n\\n\",\n",
              "  'bart_summary': \"Search-based software engineering reformulates the problem of software engineering as 'computational search problems' in order to find an optimal or near-optimal solution for the search problems. Hill Climbing, simulated annealing, genetic algorithm are popular search techniques. Testing is widely research areas of SBSE. This paper provides an analysis between different application areas in which search-based optimization has applied and techniques used for those areas. This analysis can be helpful in future for researchers to get an impression about which search techniques are used to address the different problem.\",\n",
              "  'gensim_summary': 'This paper discusses the most popular meta-heuristics techniques applied in search-based software engineering (SBSE): Hill Climbing, simulated annealing, genetic algorithm.\\nare genetic algorithms This analysis can be helpful in future for researchers in the field of SBSE to get an impression about which search techniques are used to address the different problem in software testing.\\nargumentative score = Argumentative Sentence Classifier(s_i)',\n",
              "  'lexrank_summary': \" Search-based software engineering reformulates the problem of software engineering as 'computational search problems' in order to find an optimal or near-optimal solution for the search problems. This paper provides an analysis between different application areas in which search-based optimization has applied and techniques used for those areas. The most considered search techniques in SBSE is a Genetic Algorithm. are genetic algorithms This analysis can be helpful in future for researchers in the field of SBSE to get an impression about which search techniques are used to address the different problem in software testing.\",\n",
              "  'lsa_summary': ' Fitness function distinguish between solutions and direct search to find an optimal solution. This paper discusses the most popular meta-heuristics techniques applied in search-based software engineering (SBSE): Hill Climbing, simulated annealing, genetic algorithm. This paper focuses on the popular application areas of SBSE in testing. The most considered search techniques in SBSE is a Genetic Algorithm.',\n",
              "  'summary_BigBird': ['the field of software engineering ( sse ) is widely research areas. the field of software engineering ( sse ) is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research areas. is widely research'],\n",
              "  'summary_google_pegasus': ['This paper discusses the most popular meta-heuristics techniques applied in search-based software engineering (SBSE): Hill Climbing, simulated annealing, genetic algorithm and provides an analysis between different application areas in which search-based optimization has applied and techniques used for those areas. This paper discusses the most popular meta-heuristics techniques applied in search-based software engineering (SBSE): Hill Climbing, simulated annealing, genetic algorithm and provides an analysis between different application areas in which search-based optimization has applied and techniques used for those areas.'],\n",
              "  't5_summary': \"search-based software engineering reformulates software engineering as 'computational search problems' in order to find an optimal solution for the search problems. the most popular meta-heuristics techniques in search-based software engineering are hill Climbing, simulated annealing, genetic algorithm. the most considered search techniques in SBSE is a Genetic Algorithm. the most considered search techniques in SBSE are a genetic algorithm. the most considered search techniques in SBSE are a genetic algorithm.\"},\n",
              " 'Introduction': {'_text_': \"\\nThere are many problems in the software engineering domain in which we are seeking an optimal solution or sub-optimal solution. Predominantly, problems with a large set of solution spaces where the optimal or near-optimal solution needs to obtain. Some examples <cit.> are mentioned below which belongs to the different domains of software engineering <cit.>.\\n\\n\\n  * Requirement optimization: What is the set of requirements that balances software development cost and customer satisfaction?\\n\\n  * Design: What is the best way to structure the architecture of this system to enhance its maintainability?\\n\\n  * Resource Utilization: What is the best allocation of resources to this software development project?\\n\\n  * Testing: What is the smallest set of test cases that covers all branches in this program?\\n\\n  * Maintenance: What is the best sequence of re-factoring steps to apply to this system?\\n\\nAll these questions are optimization problems in which search-based software engineering (SBSE) is well adapted and can successfully reformulate such problems as search-based optimization problems<cit.>.\\nSBSE is the type of meta-heuristic technique which applies search-based optimization. The meta-heuristic technique is a higher-level technique,  applied to find and generate the solution to an optimization problem.  Meta-heuristic techniques select a heuristic that can provide an adequately good solution to an optimization problem. In SBSE, the term ‘search' is used to mention ‘meta-heuristic search-based optimization techniques’  that is used, it should not be confused as ‘ textual or hyper-textual search' <cit.>. \\nThe main goal of SBSE is to convert problems of software engineering from human-based search to machine-based search <cit.>. The main motive behind this is rather than demanding humans to solve the monotonous, error-prone tasks exploit humans creativity and machines tenacity and reliability to solve the tasks<cit.>.\\nFor example <cit.>, software engineering needs to fulfil a set of requirements that can achieve the highest customer satisfaction. On the other hand, he also needs to keep track of software development costs while fulfilling these requirements such that it does not exceed the budget of software development cost. So in many situations like that, it is tedious and time-consuming for a software engineer to select the best solution that maintains the balance between both criteria <cit.>. SBSE convert such software engineers problems as a 'search problem'  and search techniques are used to guide through the optimal solution.    \\nA wide range of search-based optimization techniques is applied in SBSE. Section 2 provides an overview of the most widely considered search techniques that have been applied in search-based software engineering, including hill-climbing, simulated annealing and genetic algorithm<cit.>. \\n There are basically  two key indicators of Search-based software engineering <cit.>:\\n\\n\\n  * The choice of the representation of the problem.\\n\\n  * The definition of the fitness function. \\n\\nFigure 1 shows the architecture of SBSE with these two key indicators <cit.>.\\nThis simplicity with only two factors makes it easier for a software engineer to implement search-based optimization. Software engineers have a suitable representation of their problems, defined from the problem data. Furthermore, the problems in software engineering are correlated with software metrics which served as primary candidates for associated fitness function <cit.>. Software metrics evaluate the quality of solution on different properties specific to the problem for which an optimal solution needs to be found.  Fitness function guides the search process to choose the optimal solution from the given set of possible solutions. In metaheuristic, The fitness function evaluates a solution on how much it is closer to the optimum solution for the desired search problem. For example, if a software engineer wants to search for the set of test cases that covers all branches of a given problem <cit.>. For this testing problem, fitness function can be selected is a branch coverage of the given set of test cases and the objective of the search is to maximize the branch coverage. Next section, discusses popular search techniques used in SBSE using fitness function.\\n\\nSBSE is employed throughout in the all stages of the software engineering life cycle from requirements, design, testing, project planning, project maintenance and re-engineering <cit.>. \\n\\n Figure 2 shows the proportion of papers of SBSE in different fields of software engineering <cit.>. It can be noticed from the diagram that a large proportion of the papers belongs to the Testing (54%). It highlights that testing problems are well suited for SBSE. Section 3 discusses more regarding use of SBSE in testing and reviews the application areas of SBSE in the testing. Section 4 provides an analysis between the techniques and application of SBSE in testing.\\n\",\n",
              "  'bart_summary': 'SBSE is the type of meta-heuristic technique which applies search-based optimization. It is employed in the software engineering, design, testing planning, project maintenance and re-engineering. SBSE uses a fitness function to evaluate a solution on how much it is closer to the optimum solution for the desired search problem. The main goal of SBSe is to convert problems of software engineering from human-based search to machine-basedsearch. The aim is to exploit humans creativity and machines tenacity and reliability to solve the tasks.',\n",
              "  'gensim_summary': \"SBSE is the type of meta-heuristic technique which applies search-based optimization.\\nThe main goal of SBSE is to convert problems of software engineering from human-based search to machine-based search <cit.>.\\nSBSE convert such software engineers problems as a 'search problem'  and search techniques are used to guide through the optimal solution.\\nA wide range of search-based optimization techniques is applied in SBSE.\\nFitness function guides the search process to choose the optimal solution from the given set of possible solutions.\\nFor example, if a software engineer wants to search for the set of test cases that covers all branches of a given problem <cit.>.\\nFor this testing problem, fitness function can be selected is a branch coverage of the given set of test cases and the objective of the search is to maximize the branch coverage.\\nNext section, discusses popular search techniques used in SBSE using fitness function.\",\n",
              "  'lexrank_summary': \" * Resource Utilization: What is the best allocation of resources to this software development project? * Testing: What is the smallest set of test cases that covers all branches in this program? SBSE convert such software engineers problems as a 'search problem'  and search techniques are used to guide through the optimal solution. A wide range of search-based optimization techniques is applied in SBSE.\",\n",
              "  'lsa_summary': \" For example <cit.>, software engineering needs to fulfil a set of requirements that can achieve the highest customer satisfaction. SBSE convert such software engineers problems as a 'search problem'  and search techniques are used to guide through the optimal solution. Section 2 provides an overview of the most widely considered search techniques that have been applied in search-based software engineering, including hill-climbing, simulated annealing and genetic algorithm<cit.>. This simplicity with only two factors makes it easier for a software engineer to implement search-based optimization.\",\n",
              "  'summary_BigBird': ['in this paper, we propose a method of testing for optimal solutions of search-based optimization problems.<n> the method of testing for optimal solutions of search-based optimization problems is based on a fitness function.<n> the method of testing for optimal solutions of search-based optimization problems is based on a fitness function. <n> [ [ section ] ] in this paper, we propose a method of testing for optimal solutions of search-based optimization problems.<n> the method of testing for optimal solutions of search-based optimization problems is based on a fitness function. <n> [ [ section ] ] in this paper, we propose a method of testing for optimal solutions of search-based optimization problems '],\n",
              "  'summary_google_pegasus': ['In this article, I will describe search-based software engineering (SBSE) and how it can be used to solve problems of software engineering in which human-based search techniques are not well adapted and can successfully reform such problems as search-based optimization problems, in which human-based search techniques are not well adapted and can successfully reform such problems as search-based optimization problems, in which search techniques are not well adapted and can successfully reform such problems as search-based optimization problems, in which search techniques are not well adapted and can successfully reform such problems as search-based optimization problems, in which search techniques are not well adapted and can successfully reform such problems as search-based optimization problems, in which search techniques are not well adapted and'],\n",
              "  't5_summary': 'software engineering needs to fulfil a set of requirements that can achieve the highest customer satisfaction. a large proportion of papers belong to the Testing (54%). the results of the tests are based on the results of the tests. the results of the tests are based on the results of the tests. the results of the tests are based on the results of the tests. the results of the tests are based on the results of the tests. the results of the tests are based on the results of the tests'},\n",
              " 'SBSE techniques': {'_text_': \"\\nThis section provides an overview of most commonly applied search techniques applied in SBSE. Random Search is one of the simplest technique which does not use a fitness function<cit.>. In a random search, a solution is selected randomly from the set of candidate solutions until a desirable solution with high fitness value is found. Random search is unguided as it does not use fitness function. Random search is often failed to find the optimal solution for a given search problem when desire solution occupies a very small part of the set of solutions <cit.>. If guidance is provided in search by problem-specific fitness function which scores the set of solutions with respect to 'suitability for solving the problem' <cit.> better search result can be obtained. Following part of section highlights the three most widely used search-based optimization techniques applied in SBSE which uses the fitness function to find the optimal solution <cit.>. \\n\\n\\n\\n §.§  Hill Climbing\\n\\nThe simplest form of search technique using fitness function is hill climbing. Algorithm 1 shows the pseudo-code of hill-climbing  <cit.>.  As can be seen from the algorithm 1 that solution s is selected randomly from the set of candidate solutions ( Solution space S).  At each iteration, the elements of a set of ‘near-neighbours N(s)' to the current solution are considered. \\n\\nA set of ‘near-neighbours N(s)'  are solutions which are similar but differ with slight variation in ordinal scale to the current solution (s).  Hill climbing explores the all neighbouring solution candidates one by one and selects the first neighbouring solution which has higher fitness value than the current solution.  Hill-climbing algorithm keeps on searching in the  set of ‘near-neighbours N(s)' for an optimal solution until it finds solution with has a higher fitness value that currently selected solution( fit(s') ≥ fit(s) ) .\\n\\nPseudo code of the hill-climbing <cit.>  \\n \\n \\n Select a random starting solution  s ∈ S\\n Select s' ∈ N(s) such that fit(s') > fit(s)\\n s ← s' \\n fit(s) ≥ fit(s') , ∀ s' ∈ N(s) \\n\\n\\n So, Hill climbing explores neighbouring solutions of the currently selected solution in iterations to find optimal solution <cit.>. Hill climbing can find a locally optimal solution but not necessarily a globally optimal solution<cit.>. Hill climbing is not able to reach the global maximum state if it traps in one of the following region: Local Maximum, Plateau and  Ridge. Figure 3 represents all of these region where hill climbing not able to find optimal solution. \\n\\n At a local maximum, a set of near neighbours have a lower fitness value. So, hill climbing will not move to the worst state and terminate itself. Local maximum can be overcome if whenever the search reaches to such state, the algorithm backtracks to the previous state in and directs search to a new path. \\n Plateau is a region where all neighbourhood candidates have the same values. Hence, the search will not be able to select the best direction. However, it can be overcome by jumping from the plateau region to non-plateau region. Ridge is a point where a set of near neighbours have peak movement in the downward side and it causes algorithms to terminate when entering in that state.  However, the ridge can be avoided by jumping from those regions to another region and restarts the search.\\n    \\n\\n\\n §.§ Simulated Annealing\\n\\nSimulated annealing is introduced by Kirkpatrick <cit.>. Simulated annealing is originally inspired by the process of annealing in the material. Annealing is the process of heating and cooling a material to change its physical properties due to the changes in its internal structure <cit.>. As the metal cools its new structure becomes fixed, consequently causing the metal to retain its newly obtained properties. Simulated annealing does the same by using the variable called as 'Temperature (t)'.  Algorithm 2 illustrates the Pseudo-code for the Simulated Annealing algorithm  <cit.>.\\n\\nPseudo code of the simulated annealing <cit.>  \\n \\n Select a starting solution s ∈ S\\n Select an initial temperature t > 0\\nit ← 0\\nSelect s' ∈ N(S) at random\\nΔ e ← fit(s') - fit(s)\\nΔ e <0  \\ns ← s'\\nGenerate random number r,  0 ≤ r < 1\\nif r < e^-δ/t then s ← s'\\nit ← it+1\\n it = numsolns.\\nDecrease t according to cooling schedule\\nStopping Condition Reached\\n\\n\\n\\nIn simulated annealing initially, the temperature is set to high which allows search freely and solutions with lesser fitness values than the current solution are also accepted <cit.>. As the algorithm progresses, after every iterations value of temperature is decreased. As can be seen in algorithm 2 that at every iteration solution is selected from a set of ‘near-neighbours N(s). Here also a set of ‘near-neighbours N(s) ’ are solutions which are similar but differ with slight variation in ordinal scale to the current solution (s) <cit.>. For every selected solution its difference in the fitness value to initially selected solution is found  (Δ e ← fit(s') - fit(s)). If the fitness value of  Δ e is negative then that solution is selected. Otherwise, the search moves further and the random number r is generated. Next, The 'probability of acceptance p ' of an inferior solution (Non optimal solution) is calculated as p = e^-δ/t, where δ is the difference in fitness value between the current solution and inferior solution in set of near neighbours being considered, and t is the current value of the temperature <cit.>. If random value is less then probability then the solution is selected. Iteration is performed for every solution in solution space. After that, the value of temperature is decreased.  Reduction in temperatures, causing the search to move towards the poorer solutions in the neighbourhood <cit.>.  Consequently, when a freezing point is reached simulated annealing behaves identically as hill climbing <cit.>.  Freezing point is a point where the temperature is set to 0.\\nInitially, the temperature is set to high in simulated annealing allowing the search to explore further states in the solution space with lesser fitness values also allows to get rid of local optima <cit.>.  So, simulated Annealing can be able to overcome from the local maximum region, unlike hill-climbing <cit.>. \\nHill climbing and simulated annealing are types of local search algorithms, as they operate with\\nreference to one candidate solution at any a time while in the global searches reference to multiple solutions at a time. Genetic Algorithm is one of the types of global searches <cit.>. Next, section provides an overview of Genetic Algorithms which is a type of global search algorithm.\\n\\n\\n\\n §.§ Genetic Algorithms\\n\\nGenetic Algorithms are inspired by Darwinian evolution <cit.>. Genetic algorithm is a type of global search algorithm. So search considers a set of candidate solutions at a time.  The genetic algorithm starts with an initial set of candidate solutions known as population P <cit.>.  Population generation is an iterative process where each iteration are called generations and the members of the population are called chromosomes. The genetic algorithm represents a set of candidate solutions as a vector of components. Genetic algorithm especially uses a binary representation. So each candidate solutions can be seen as strings of 1s and 0s <cit.>. However, more natural representations to the problem may also be used such as a list of floating-point values <cit.>.\\n\\n\\n\\nPseudo code of the Genetic Algorithm <cit.>  \\n \\nRandomly generate or seed initial population P\\nEvaluate fitness of each individual in P\\nSelect parents from P according to selection mechanism\\nRecombine parents to form new offspring\\nConstruct new population P' from parents and offspring\\nMutate P'\\nP ← P'\\n Stopping Condition Reached\\n\\n\\n\\n The main loop of a Genetic Algorithm is displayed in algorithm 3. As can be seen in algorithm 3  <cit.>: the genetic algorithm starts with a randomly chosen population P. Population generation process repeated in iterations until algorithm terminates. In each iteration, each individual in the population P is evaluated for the fitness.   After that at each iteration following operations are performed on the member of populations for the generations of the subsequent solutions: selection, crossover, mutations.\\n\\n\\n  * Selection: In the selection, best-performing individuals of the parents (previous generations ) are retained to one generation to the next. So the solution with more fitness values for the optimization problem is selected in the next generation through selection. \\n\\n\\n\\n  * Crossover: In the crossover, individuals of parents are recombined to form children for the next generation.  In the crossover, recombination is based on the similarity in the parent's node.  Solutions with higher fitness value are considered first as they fit well for the search problem. For example,\\ntwo strings of the parents ‘111’ and ‘000’ can be spliced at position 2 to form two children ‘100’ and ‘011’<cit.>. \\n\\n\\n\\n  * Mutation: In mutation, individuals of the previous generation (parents) are mutated to take on the random value. Mutation involves randomly flipping bits of the parents. Mutation allows avoiding local optimization as search explores more solutions in the search space.  \\n\\n\\nFinally,  the next generation of the population is then selected in the ‘reinsertion’ phase, and again the new individuals are evaluated for the fitness <cit.>. The cycle is repeated until algorithm terminates. Figure 4 shows the flowchart for the genetic algorithm with operations selection, crossover and mutation. Here, termination criteria for the genetic algorithm vary based on the requirements. It could be any of the following:  desire solution found, resources exhausted, a fixed number of population generations, time limit <cit.>. \\n\\n \\n \\n\\n Genetic algorithms have been the most widely applied search technique in SBSE compare to other search techniques.\\n \\n \\n\",\n",
              "  'bart_summary': 'This section provides an overview of most commonly applied search techniques applied in SBSE. In a random search, a solution is selected randomly from the set of candidate solutions until a desirable solution with high fitness value is found. Simulated Annealing is originally inspired by the process of annealing in the material. The algorithm for the simulated Annealing algorithm does not use the fitness function. The simplest form of search technique using fitness function is hill climbing. Hill climbing can find a locally optimal solution but not necessarily a globally optimal solution.',\n",
              "  'gensim_summary': \"In a random search, a solution is selected randomly from the set of candidate solutions until a desirable solution with high fitness value is found.\\nFollowing part of section highlights the three most widely used search-based optimization techniques applied in SBSE which uses the fitness function to find the optimal solution <cit.>.\\nThe simplest form of search technique using fitness function is hill climbing.\\nAs can be seen from the algorithm 1 that solution s is selected randomly from the set of candidate solutions ( Solution space S).\\nHill climbing explores the all neighbouring solution candidates one by one and selects the first neighbouring solution which has higher fitness value than the current solution.\\nHill-climbing algorithm keeps on searching in the  set of ‘near-neighbours N(s)' for an optimal solution until it finds solution with has a higher fitness value that currently selected solution( fit(s') ≥ fit(s) ) .\\nSo, Hill climbing explores neighbouring solutions of the currently selected solution in iterations to find optimal solution <cit.>.\\nHill climbing is not able to reach the global maximum state if it traps in one of the following region: Local Maximum, Plateau and  Ridge.\\nIn simulated annealing initially, the temperature is set to high which allows search freely and solutions with lesser fitness values than the current solution are also accepted <cit.>.\\nAs can be seen in algorithm 2 that at every iteration solution is selected from a set of ‘near-neighbours N(s).\\nInitially, the temperature is set to high in simulated annealing allowing the search to explore further states in the solution space with lesser fitness values also allows to get rid of local optima <cit.>.\\nSo, simulated Annealing can be able to overcome from the local maximum region, unlike hill-climbing <cit.>.\\nHill climbing and simulated annealing are types of local search algorithms, as they operate with\\nGenetic Algorithm is one of the types of global searches <cit.>.\\nSo search considers a set of candidate solutions at a time.\\nThe genetic algorithm starts with an initial set of candidate solutions known as population P <cit.>.\\nThe genetic algorithm represents a set of candidate solutions as a vector of components.\\nPopulation generation process repeated in iterations until algorithm terminates.\\nAfter that at each iteration following operations are performed on the member of populations for the generations of the subsequent solutions: selection, crossover, mutations.\\nSo the solution with more fitness values for the optimization problem is selected in the next generation through selection.\\nSolutions with higher fitness value are considered first as they fit well for the search problem.\",\n",
              "  'lexrank_summary': \" In a random search, a solution is selected randomly from the set of candidate solutions until a desirable solution with high fitness value is found. As can be seen in algorithm 2 that at every iteration solution is selected from a set of ‘near-neighbours N(s). For every selected solution its difference in the fitness value to initially selected solution is found  (Δ e ← fit(s') - fit(s)). Genetic algorithm is a type of global search algorithm.\",\n",
              "  'lsa_summary': ' As can be seen in algorithm 2 that at every iteration solution is selected from a set of ‘near-neighbours N(s). Hill climbing and simulated annealing are types of local search algorithms, as they operate with reference to one candidate solution at any a time while in the global searches reference to multiple solutions at a time. However, more natural representations to the problem may also be used such as a list of floating-point values <cit.>. Solutions with higher fitness value are considered first as they fit well for the search problem.',\n",
              "  'summary_BigBird': [\"in this paper, we study the problem of finding an optimal solution to the equation :  what is the temperature of the solution? ''.<n> we consider the problem of finding an optimal solution to the equation :  what is the temperature of the solution? ''.<n> we study the problem of finding an optimal solution to the equation :  what is the temperature of the solution? ''. in this paper, we study the problem of finding an optimal solution to the equation :  what is the temperature of the solution? ''. we consider the problem of finding an optimal solution to the equation :  what is the temperature of the solution?\"],\n",
              "  'summary_google_pegasus': ['Search-based optimisation (SBSE) is a branch of computer science which deals with the problem of finding the optimal solution to a given problem in terms of fit and fit-to-fitness of a set of candidate solutions to a set of search problems, in terms of fit and fit-to-fitness of a set of candidate solutions to a set of search problems, in terms of fit and fit-to-fitness of a set of candidate solutions to a set of search problems, in terms of fit and fit-to-fitness of a set of candidate solutions to a set of search problems, in terms of fit and fit-to-fitness of a set of search problems, in terms of fit and'],\n",
              "  't5_summary': 'a random solution is selected randomly from the set of candidate solutions. a set of ‘near-neighbours N(s)’ are solutions which are similar but differ with slight variation in ordinal scale to the current solution. hill climbing can find a locally optimal solution but not necessarily a globally optimal solutioncit. simulated annealing is a type of global search algorithm. a genetic algorithm is a type of global search algorithm.'}}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hkfsSgJ_WgI4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}