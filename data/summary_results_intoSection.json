{
    "_text_": "Per-instance Algorithm Selection (AS) denotes the problem of recommending an algorithm that appears to be most suitable for a given instance of a problem class. The suitability is assessed with respect to a specific performance criterion, such as solution quality or runtime.The latter is of special interest when dealing with computationally hard problems, such as the Boolean satisfiability problem (SAT) , the traveling salesperson problem (TSP) , or constraint satisfaction problems (CSP) ).To deal with censored data, several approaches consider them as missing values and apply imputation techniques to replace these values . While the latter approach appropriately captures the information provided by a censored observation, namely that the runtime exceeds the cutoff time $C$, the former turns it into unduly precise information and comes with the risk of incorporating a bias in the learning process.%based on the observations on other instances, thereby distorting the actual ground truth for training. More specifically, the information that is available when an instance has a censored label is that the runtime exceeds the cutoff time $C$, i.e., the ground truth value lies in the interval $(C,infty)$.In this paper, we propose to consider AS as a so-called superset learning problem , where the learner induces a (precise) predictive model from possibly imprecise training data. More concretely, we learn a regression model for runtime prediction from training instances that are either precisely labeled or labeled with an interval of the form $(C, infty)$.This is not only a just representation of the (weak albeit non-void) information that the true runtime exceeds $C$, but, as will be seen, also offers an efficient way for handling censored data. In our experimental evaluation, we show that methods based on superset learning can induce (linear) models that outperform na\"ive strategies for dealing with censored data in AS.",
    "bart_summary": "Per-instance Algorithm Selection (AS) denotes the problem of recommending an algorithm that appears to be most suitable for a given instance of a problem class. To deal with censored data, several approaches consider them as missing values and apply imputation techniques to replace these values. In this paper, we propose to consider AS as a so-called superset learning problem",
    "summary_BigBird": [
        "we consider as socalled superset learning problem : where the learning process is to learn a regression model from possibly imprecise training data.<n> specifically, we consider as socalled superset learning problem : where the learning process is to learn a predictive model from possibly imprecise training data.<n> this paper we propose to consider as socalled superset learning problem"
    ],
    "gpt_summary": "Per-instance Algorithm Selection (AS) denotes the problem of recommending an algorithm that appears to be most suitable for a given instance of a problem class. The suitability is assessed with respect to a specific performance criterion, such as solution quality or runtime.The latter is of special interest when dealing with computationally hard problems, such as the Boolean satisfiability problem (SAT), the traveling salesperson problem (TSP), or constraint satisfaction problems (CSP) ).To deal with censored data, several approaches consider them as missing values and apply imputation techniques to replace these values. While the latter approach appropriately captures the information provided by a censored observation, namely that the runtime exceeds the cutoff time $C$, the former turns it into unduly precise information and comes with the risk of incorporating a bias in the learning process.%based on the observations on other instances, thereby distorting the actual ground truth for training. More specifically, the information that is available when an instance has a censored label is that the runtime exceeds the cutoff time $C$, i.e., the ground truth value lies in the interval $(C,infty)$.In this paper, we propose to consider AS as a so-called superset learning problem, where the learner induces a (precise) predictive model from possibly imprecise training data. More concretely, we learn a regression model for runtime prediction from training instances that are either precisely labeled or labeled with an interval of the form $(C, infty)$.This is not only a just representation of the (weak albeit non-void) information that the true runtime exceeds $C$, but, as will be seen, also offers an efficient way for handling censored data. In our experimental evaluation, we show that methods based on superset learning can induce (linear) models that outperform na\"ive strategies for dealing with censored data in AS. We",
    "summary_google_pegasus": [
        "In this paper, we propose a new approach to per-instance algorithm selection, where the ground truth of a censored observation lies in the interval $C$, rather than in the missing values or imputation techniques used to deal with the data."
    ],
    "t5_summary": "a censored observation reveals the runtime exceeds $C$. the censored observation turns it into unduly precise information. the former turns it into unduly precise information. imputation techniques are used to replace these values.",
    "gensim_summary": "More specifically, the information that is available when an instance has a censored label is that the runtime exceeds the cutoff time $C$, i.e., the ground truth value lies in the interval $(C,infty)$.In this paper, we propose to consider AS as a so-called superset learning problem , where the learner induces a (precise) predictive model from possibly imprecise training data.",
    "lexrank_summary": " Per-instance Algorithm Selection (AS) denotes the problem of recommending an algorithm that appears to be most suitable for a given instance of a problem class. The suitability is assessed with respect to a specific performance criterion, such as solution quality or runtime.The latter is of special interest when dealing with computationally hard problems, such as the Boolean satisfiability problem (SAT) , the traveling salesperson problem (TSP) , or constraint satisfaction problems (CSP) ).To deal with censored data, several approaches consider them as missing values and apply imputation techniques to replace these values . More specifically, the information that is available when an instance has a censored label is that the runtime exceeds the cutoff time $C$, i.e., the ground truth value lies in the interval $(C,infty)$.In this paper, we propose to consider AS as a so-called superset learning problem , where the learner induces a (precise) predictive model from possibly imprecise training data.",
    "lsa_summary": " The suitability is assessed with respect to a specific performance criterion, such as solution quality or runtime.The latter is of special interest when dealing with computationally hard problems, such as the Boolean satisfiability problem (SAT) , the traveling salesperson problem (TSP) , or constraint satisfaction problems (CSP) ).To deal with censored data, several approaches consider them as missing values and apply imputation techniques to replace these values . More concretely, we learn a regression model for runtime prediction from training instances that are either precisely labeled or labeled with an interval of the form $(C, infty)$.This is not only a just representation of the (weak albeit non-void) information that the true runtime exceeds $C$, but, as will be seen, also offers an efficient way for handling censored data. In our experimental evaluation, we show that methods based on superset learning can induce (linear) models that outperform na\"ive strategies for dealing with censored data in AS."
}
