{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "latex_file_parser.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "807Dl_jh6V3z"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QrZp7BXwJeK",
        "outputId": "bb7b0649-9a36-46ac-b6c0-3340ed4d87a8"
      },
      "source": [
        "! pip install pylatexenc"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pylatexenc\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 24.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 20 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 30 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 40 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 92 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 162 kB 5.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136833 sha256=5dfd688c1ab8967ad07499938670425def37d262ba367ecb55d38b2595f8d3a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/8a/f5/33ee79d4473eb201b519fa40f989b842e373237395a3421f52\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: pylatexenc\n",
            "Successfully installed pylatexenc-2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG3phv7kwjHa"
      },
      "source": [
        "import re\n",
        "from pylatexenc.latexwalker import LatexWalker, LatexEnvironmentNode\n",
        "from pylatexenc.latex2text import LatexNodes2Text"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CQ5GL1zPX8i"
      },
      "source": [
        "## Pre-processing latext file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc4LTiWrwLgr"
      },
      "source": [
        "file_path = r\"/content/drive/MyDrive/TextSummarizationResults/main.tex\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIn32x6VP2I-"
      },
      "source": [
        "latex_file_list = open(file_path).readlines()\n",
        "latex_file_wo_comments =[]\n",
        "for line in latex_file_list:\n",
        "  if not line.startswith(\"%\"):\n",
        "    latex_file_wo_comments.append(line)\n",
        "latex_text_wo_comments = \"\".join(latex_file_wo_comments)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3BVIWo5QYBj",
        "outputId": "88fb2f4f-ea1b-432a-b19c-55a578bbcc71"
      },
      "source": [
        "len(latex_file_wo_comments)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "275"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1Pljp0sQbns",
        "outputId": "a7b2341e-31a6-42d4-d771-17ac5b44cbbd"
      },
      "source": [
        "latex_file_wo_comments[0:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\\\documentclass[runningheads]{llncs}\\n',\n",
              " '\\\\usepackage{graphicx}\\n',\n",
              " '\\\\usepackage[usenames,dvipsnames]{xcolor}\\n',\n",
              " '\\\\usepackage{amsmath}\\n',\n",
              " '\\\\usepackage{amssymb}\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx0n8OShyrA4"
      },
      "source": [
        "figure_conent = re.findall(r'\\\\begin{figure}(.*?)\\\\end{figure}',latex_text_wo_comments , re.S)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffmibjSmHEAK",
        "outputId": "af158626-84e8-43d2-a142-2d9342d43c90"
      },
      "source": [
        "len(figure_conent)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AjHcLirHF1a"
      },
      "source": [
        "equation_conent = re.findall(r'\\\\begin{equation}(.*?)\\\\end{equation}',latex_text_wo_comments , re.S)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njgj4cIGHT8C",
        "outputId": "4d9c5931-f3ed-4456-ce27-2abb65bcb94f"
      },
      "source": [
        "equation_conent"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n    s^{*}(I) \\\\defeq \\\\argmin_{A \\\\in \\\\mathcal{A}} \\\\mathbb{E} \\\\, [m(I,A)] \\\\, ,\\n',\n",
              " '\\n    \\\\hat{s}(I) \\\\defeq \\\\argmin_{A \\\\in \\\\mathcal{A}} \\\\widehat{m}(I,A)\\n',\n",
              " '\\n    \\\\left(I, A_1 \\\\succ \\\\cdots \\\\succ A_z \\\\right) \\\\in \\\\mathbb{R}^d \\\\times \\\\mathcal{R}(\\\\mathcal{A}) \\\\, ,\\n',\n",
              " \"\\n    \\\\mathcal{D} \\\\defeq \\\\Big\\\\{ \\\\left( I_n, m_1'(I_n) , \\\\ldots , m_K'(I_n) \\\\right) \\\\Big\\\\}_{n=1}^N   \\\\, , \\n\",\n",
              " '\\n\\\\label{eq:convex_combination}\\n    L(\\\\mathcal{D},v) \\\\defeq \\\\lambda L_\\\\text{RANK}\\\\left(\\\\mathcal{D},v\\\\right) + \\\\left(1 - \\\\lambda\\\\right) L_\\\\text{REG}\\\\left(\\\\mathcal{D},v\\\\right) \\\\, ,\\n',\n",
              " '\\n    \\\\label{eq:mse}\\n    L_\\\\text{REG}(R_n,v) \\\\defeq \\\\frac{1}{|R_n|} \\\\sum_{\\\\left(I_n, y_{k,n}\\\\right) \\\\in R_n}   \\n    \\\\big(  v_k(I_n)  - y_{k,n} \\\\big)^2 \\\\, .\\n',\n",
              " '\\n\\\\label{eq:hinge_loss}\\nL_\\\\text{RANK}(P_n,v) \\\\defeq   \\\\binom{|P_n|}{2}^{-1} \\\\!\\\\!\\\\!\\\\!\\\\!\\\\! %{{| P_n|} \\\\choose 2}^{-1} \\n\\\\sum_{(I_n, i , j)} \\\\!\\\\!\\\\!\\\\! \\\\ell \\\\Big( \\n\\\\epsilon -  v_i(I_n) + v_j(I_n)  \\\\Big) \\\\, ,\\n',\n",
              " '\\n\\\\label{eq:pl_nll}\\nL_\\\\text{RANK}(P_n,v) \\\\defeq   \\\\binom{|P_n|}{2}^{-1} \\\\!\\\\!\\\\!\\\\!\\\\!\\\\! %{{| P_n|} \\\\choose 2}^{-1} \\n\\\\sum_{(I_n, i , j)} \\\\!\\\\!\\\\!\\\\! \\n\\\\ell \\\\big( v_i(I_n) , v_j(I_n) \\\\big) \\\\, ,\\n',\n",
              " '\\n\\\\ell \\\\big( x, y \\\\big) = \\n\\\\log \\\\big( \\\\exp(- x ) +  \\\\exp( - y ) \\\\big) + x \\\\, .\\n',\n",
              " '\\\\label{eq:linear_model}\\n    v_k(I) = \\\\boldsymbol{w}_k^T I \\\\, ,\\n',\n",
              " '\\n\\t\\\\label{eq:kendall_tau}\\n\\t\\\\tau(\\\\pi,\\\\hat{\\\\pi}) = \\\\frac{C-D}{\\\\sqrt{(C+D+T_{\\\\pi})\\\\cdot(C+D+T_{\\\\hat{\\\\pi}})}} \\\\, ,\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpBxoHNWHVYS",
        "outputId": "70d4fb81-f1bb-4471-badb-d2525baa65cb"
      },
      "source": [
        "len(equation_conent)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtGXK14ZHYia"
      },
      "source": [
        "table_conent = re.findall(r'\\\\begin{table}(.*?)\\\\end{table}',latex_text_wo_comments , re.S)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFQ0CKwgKlnj",
        "outputId": "99579854-174e-43ea-a8d5-59ba9c08d899"
      },
      "source": [
        "table_conent"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"[ht]\\n    \\\\caption{Number of scenarios for which each configuration achieved the best (average) performance according to Kendall's $\\\\tau$ coefficient resp.\\\\ PAR10 score. Recall that $\\\\lambda=0$ means pure regression, $\\\\lambda \\\\in (0,1)$ a hybrid approach, and $\\\\lambda = 1$ pure ranking. %The results for each scenario have first been summarized taking the mean, before the number of wins was counted.\\n    }\\n    \\\\centering\\n\\\\begin{adjustbox}{width={7cm}}\\n\\\\begin{tabular}{|l|rrr|rrr|}\\n\\\\hline\\n\\\\multirow{2}{*}{Model} & \\\\multicolumn{3}{c|}{$\\\\tau$}                         & \\\\multicolumn{3}{c|}{PAR10}                          \\\\\\\\ \\\\cline{2-7} \\n                      & $\\\\lambda = 0$ & $\\\\lambda \\\\in (0,1)$ & $\\\\lambda = 1$ & $\\\\lambda = 0$ & $\\\\lambda \\\\in (0,1)$ & $\\\\lambda = 1$ \\\\\\\\ \\\\hline\\nPL-LM                  & 0             & \\\\textbf{6}          & 0             & 0             & \\\\textbf{5}          & 1             \\\\\\\\\\nPL-QM                  & 0             & \\\\textbf{3}          & \\\\textbf{3}    & 1             & \\\\textbf{3}          & 2             \\\\\\\\\\nPL-NN                  & 0             & \\\\textbf{4}          & 2             & 1             & \\\\textbf{5}          & 0             \\\\\\\\ \\\\hline\\nHinge-LM               & 0             & \\\\textbf{4}          & 2            & 1             & \\\\textbf{4}           & 1              \\\\\\\\\\nHinge-QM               & 0             & \\\\textbf{3}          & \\\\textbf{3}    & 1            & \\\\textbf{3}            & 2          \\\\\\\\\\nHinge-NN               & 0             & \\\\textbf{5}          & 1             & 1             & \\\\textbf{4}          & 1             \\\\\\\\ \\\\hline\\n\\\\end{tabular}\\n\\\\end{adjustbox}\\n    \\\\label{tab:summary_results}\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tj_QFTxKony"
      },
      "source": [
        "latex_codes = table_conent + equation_conent + figure_conent"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4fU6rx3KzQJ",
        "outputId": "da2d5469-d135-444f-c2a6-279cf014617e"
      },
      "source": [
        "len(latex_codes)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCOVXgObK45y"
      },
      "source": [
        "latex_text_cleaned = latex_text_wo_comments\n",
        "for latex_code in latex_codes:\n",
        "  latex_text_cleaned = latex_text_cleaned.replace(latex_code, \"\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4_J3op_y8JK",
        "outputId": "0556cdea-c8f5-4ba4-c13c-1aae55c07a5d"
      },
      "source": [
        "print(latex_text_cleaned[0:900])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\documentclass[runningheads]{llncs}\n",
            "\\usepackage{graphicx}\n",
            "\\usepackage[usenames,dvipsnames]{xcolor}\n",
            "\\usepackage{amsmath}\n",
            "\\usepackage{amssymb}\n",
            "\\usepackage{booktabs}\n",
            "\\usepackage{multirow}\n",
            "\\usepackage{adjustbox}\n",
            "\\usepackage[normalem]{ulem}\n",
            "\n",
            "\n",
            "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
            "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
            "\\newcommand*{\\defeq}{\\mathrel{\\vcenter{\\baselineskip0.5ex \\lineskiplimit0pt\n",
            "\t\t\t\\hbox{\\footnotesize.}\\hbox{\\footnotesize.}}}%\n",
            "\t=}\n",
            "\t\n",
            "\n",
            "\\begin{document}\n",
            "\n",
            "\\title{Hybrid Ranking and Regression\\\\ for Algorithm Selection}\n",
            "\\author{Jonas Hanselle\\orcidID{0000-0002-1231-4985} \\and\n",
            "Alexander Tornede\\orcidID{0000-0002-2415-2186} \\and\n",
            "Marcel Wever\\orcidID{0000-0001-9782-6818} \\and\n",
            "Eyke Hüllermeier\\orcidID{0000-0002-9944-4108}}\n",
            "\\authorrunning{J. Hanselle et al.}\n",
            "\\institute{Heinz Nixdorf Institut and Department of Computer Science, Paderborn University, Paderborn, Germany\\\\\n",
            "\\email{\\{jonas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dlODX8hQo3Z"
      },
      "source": [
        "## Extract absracts and sections names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVsI3JAIxClf"
      },
      "source": [
        "abstract = re.findall(r'\\\\begin{abstract}(.*?)\\\\end{abstract}',latex_text_cleaned , re.S)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7f6gtu5xJJR",
        "outputId": "3ef87fb8-97ce-4325-fe9d-539f7e473830"
      },
      "source": [
        "print(abstract)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"\\nAlgorithm selection (AS) is defined as the task of automatically selecting the most suitable algorithm from a set of candidate algorithms for a specific instance of an algorithmic problem class. While suitability may refer to different criteria, runtime is of specific practical relevance. Leveraging empirical runtime information as training data, the AS problem is commonly tackled by fitting a regression function, which can then be used to estimate the candidate algorithms' runtimes for new problem instances. In this paper, we develop a new approach to algorithm selection that combines regression with ranking, also known as learning to rank, a problem that has recently been studied in the realm of preference learning. Since only the ranking of the algorithms is eventually needed for the purpose of selection, the precise numerical estimation of runtimes appears to be a dispensable and unnecessarily difficult problem. However, discarding the numerical runtime information completely seems to be a bad idea, as we hide potentially useful information about the algorithms' performance margins from the learner. Extensive experimental studies confirm the potential of our hybrid approach, showing that it often performs better than pure regression and pure ranking methods.   \\n\\n\\n\\\\keywords{algorithm selection \\\\and hybrid loss optimization \\\\and combined ranking and regression}\\n\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn1xp-ZNxQZy"
      },
      "source": [
        "section_names = re.findall(r'\\\\section{(.*?)}',latex_text_cleaned , re.S)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc2zcZt4xSVo",
        "outputId": "b49560d9-a887-4f00-f5dd-b371a3c0811f"
      },
      "source": [
        "section_names"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Introduction',\n",
              " 'Algorithm Selection',\n",
              " 'Hybrid Ranking and Regression Losses',\n",
              " 'Models and Optimization',\n",
              " 'Evaluation',\n",
              " 'Conclusion']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pREZk-2y1AKJ"
      },
      "source": [
        "sections_tags =[]\n",
        "for section in section_names:\n",
        "  section_tag = \"\\section{\" +section + \"}\"\n",
        "  sections_tags.append(section_tag)\n",
        "\n",
        "sections_tags.append(\"\\end{document}\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79WEwySy1C6i",
        "outputId": "7aeb6167-a2a8-4e65-ae65-817971422490"
      },
      "source": [
        "sections_tags"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\\\section{Introduction}',\n",
              " '\\\\section{Algorithm Selection}',\n",
              " '\\\\section{Hybrid Ranking and Regression Losses}',\n",
              " '\\\\section{Models and Optimization}',\n",
              " '\\\\section{Evaluation}',\n",
              " '\\\\section{Conclusion}',\n",
              " '\\\\end{document}']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B-SJaqR1oJL"
      },
      "source": [
        "def find_substring(s,start_string, end_string): \n",
        "  start = s.find(start_string) + len(start_string)\n",
        "  end = s.find(end_string)\n",
        "  substring = s[start:end]\n",
        "  return substring"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX6H7izZ0efu"
      },
      "source": [
        "section_content = dict()\n",
        "for section_index in range(len(sections_tags)-1):\n",
        "  sections_text_latex = find_substring(latex_text_cleaned, sections_tags[section_index], sections_tags[section_index+ 1])\n",
        "  sections_text = LatexNodes2Text().latex_to_text(\"\".join(abstract))\n",
        "  section_content[section_names[section_index]] = sections_text"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGjy9RRE1QwU",
        "outputId": "d4cd13d0-232f-48f9-b060-910bc8de6698"
      },
      "source": [
        "section_content"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Algorithm Selection': \"\\nAlgorithm selection (AS) is defined as the task of automatically selecting the most suitable algorithm from a set of candidate algorithms for a specific instance of an algorithmic problem class. While suitability may refer to different criteria, runtime is of specific practical relevance. Leveraging empirical runtime information as training data, the AS problem is commonly tackled by fitting a regression function, which can then be used to estimate the candidate algorithms' runtimes for new problem instances. In this paper, we develop a new approach to algorithm selection that combines regression with ranking, also known as learning to rank, a problem that has recently been studied in the realm of preference learning. Since only the ranking of the algorithms is eventually needed for the purpose of selection, the precise numerical estimation of runtimes appears to be a dispensable and unnecessarily difficult problem. However, discarding the numerical runtime information completely seems to be a bad idea, as we hide potentially useful information about the algorithms' performance margins from the learner. Extensive experimental studies confirm the potential of our hybrid approach, showing that it often performs better than pure regression and pure ranking methods.   \\n\\n\\n\\n\",\n",
              " 'Conclusion': \"\\nAlgorithm selection (AS) is defined as the task of automatically selecting the most suitable algorithm from a set of candidate algorithms for a specific instance of an algorithmic problem class. While suitability may refer to different criteria, runtime is of specific practical relevance. Leveraging empirical runtime information as training data, the AS problem is commonly tackled by fitting a regression function, which can then be used to estimate the candidate algorithms' runtimes for new problem instances. In this paper, we develop a new approach to algorithm selection that combines regression with ranking, also known as learning to rank, a problem that has recently been studied in the realm of preference learning. Since only the ranking of the algorithms is eventually needed for the purpose of selection, the precise numerical estimation of runtimes appears to be a dispensable and unnecessarily difficult problem. However, discarding the numerical runtime information completely seems to be a bad idea, as we hide potentially useful information about the algorithms' performance margins from the learner. Extensive experimental studies confirm the potential of our hybrid approach, showing that it often performs better than pure regression and pure ranking methods.   \\n\\n\\n\\n\",\n",
              " 'Evaluation': \"\\nAlgorithm selection (AS) is defined as the task of automatically selecting the most suitable algorithm from a set of candidate algorithms for a specific instance of an algorithmic problem class. While suitability may refer to different criteria, runtime is of specific practical relevance. Leveraging empirical runtime information as training data, the AS problem is commonly tackled by fitting a regression function, which can then be used to estimate the candidate algorithms' runtimes for new problem instances. In this paper, we develop a new approach to algorithm selection that combines regression with ranking, also known as learning to rank, a problem that has recently been studied in the realm of preference learning. Since only the ranking of the algorithms is eventually needed for the purpose of selection, the precise numerical estimation of runtimes appears to be a dispensable and unnecessarily difficult problem. However, discarding the numerical runtime information completely seems to be a bad idea, as we hide potentially useful information about the algorithms' performance margins from the learner. Extensive experimental studies confirm the potential of our hybrid approach, showing that it often performs better than pure regression and pure ranking methods.   \\n\\n\\n\\n\",\n",
              " 'Hybrid Ranking and Regression Losses': \"\\nAlgorithm selection (AS) is defined as the task of automatically selecting the most suitable algorithm from a set of candidate algorithms for a specific instance of an algorithmic problem class. While suitability may refer to different criteria, runtime is of specific practical relevance. Leveraging empirical runtime information as training data, the AS problem is commonly tackled by fitting a regression function, which can then be used to estimate the candidate algorithms' runtimes for new problem instances. In this paper, we develop a new approach to algorithm selection that combines regression with ranking, also known as learning to rank, a problem that has recently been studied in the realm of preference learning. Since only the ranking of the algorithms is eventually needed for the purpose of selection, the precise numerical estimation of runtimes appears to be a dispensable and unnecessarily difficult problem. However, discarding the numerical runtime information completely seems to be a bad idea, as we hide potentially useful information about the algorithms' performance margins from the learner. Extensive experimental studies confirm the potential of our hybrid approach, showing that it often performs better than pure regression and pure ranking methods.   \\n\\n\\n\\n\",\n",
              " 'Introduction': \"\\nAlgorithm selection (AS) is defined as the task of automatically selecting the most suitable algorithm from a set of candidate algorithms for a specific instance of an algorithmic problem class. While suitability may refer to different criteria, runtime is of specific practical relevance. Leveraging empirical runtime information as training data, the AS problem is commonly tackled by fitting a regression function, which can then be used to estimate the candidate algorithms' runtimes for new problem instances. In this paper, we develop a new approach to algorithm selection that combines regression with ranking, also known as learning to rank, a problem that has recently been studied in the realm of preference learning. Since only the ranking of the algorithms is eventually needed for the purpose of selection, the precise numerical estimation of runtimes appears to be a dispensable and unnecessarily difficult problem. However, discarding the numerical runtime information completely seems to be a bad idea, as we hide potentially useful information about the algorithms' performance margins from the learner. Extensive experimental studies confirm the potential of our hybrid approach, showing that it often performs better than pure regression and pure ranking methods.   \\n\\n\\n\\n\",\n",
              " 'Models and Optimization': \"\\nAlgorithm selection (AS) is defined as the task of automatically selecting the most suitable algorithm from a set of candidate algorithms for a specific instance of an algorithmic problem class. While suitability may refer to different criteria, runtime is of specific practical relevance. Leveraging empirical runtime information as training data, the AS problem is commonly tackled by fitting a regression function, which can then be used to estimate the candidate algorithms' runtimes for new problem instances. In this paper, we develop a new approach to algorithm selection that combines regression with ranking, also known as learning to rank, a problem that has recently been studied in the realm of preference learning. Since only the ranking of the algorithms is eventually needed for the purpose of selection, the precise numerical estimation of runtimes appears to be a dispensable and unnecessarily difficult problem. However, discarding the numerical runtime information completely seems to be a bad idea, as we hide potentially useful information about the algorithms' performance margins from the learner. Extensive experimental studies confirm the potential of our hybrid approach, showing that it often performs better than pure regression and pure ranking methods.   \\n\\n\\n\\n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKgoOX0D1w4Y"
      },
      "source": [
        "abstract_text = LatexNodes2Text().latex_to_text(\"\".join(abstract))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRL6s_E43PXr"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "gfB8lp4E2ouN",
        "outputId": "fa100c4e-6097-4bd7-9716-16851a5aae4b"
      },
      "source": [
        "abstract_text"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nAlgorithm selection (AS) is defined as the task of automatically selecting the most suitable algorithm from a set of candidate algorithms for a specific instance of an algorithmic problem class. While suitability may refer to different criteria, runtime is of specific practical relevance. Leveraging empirical runtime information as training data, the AS problem is commonly tackled by fitting a regression function, which can then be used to estimate the candidate algorithms' runtimes for new problem instances. In this paper, we develop a new approach to algorithm selection that combines regression with ranking, also known as learning to rank, a problem that has recently been studied in the realm of preference learning. Since only the ranking of the algorithms is eventually needed for the purpose of selection, the precise numerical estimation of runtimes appears to be a dispensable and unnecessarily difficult problem. However, discarding the numerical runtime information completely seems to be a bad idea, as we hide potentially useful information about the algorithms' performance margins from the learner. Extensive experimental studies confirm the potential of our hybrid approach, showing that it often performs better than pure regression and pure ranking methods.   \\n\\n\\n\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}